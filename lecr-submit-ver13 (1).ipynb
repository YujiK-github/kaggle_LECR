{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5076829",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-03-08T04:25:24.837234Z",
     "iopub.status.busy": "2023-03-08T04:25:24.836372Z",
     "iopub.status.idle": "2023-03-08T04:25:24.848348Z",
     "shell.execute_reply": "2023-03-08T04:25:24.847381Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.024045,
     "end_time": "2023-03-08T04:25:24.853158",
     "exception": false,
     "start_time": "2023-03-08T04:25:24.829113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "%env TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50e8df34",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-03-08T04:25:24.864370Z",
     "iopub.status.busy": "2023-03-08T04:25:24.864087Z",
     "iopub.status.idle": "2023-03-08T04:25:24.872081Z",
     "shell.execute_reply": "2023-03-08T04:25:24.870776Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.015576,
     "end_time": "2023-03-08T04:25:24.874063",
     "exception": false,
     "start_time": "2023-03-08T04:25:24.858487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing get_topic_context.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile get_topic_context.py\n",
    "\"\"\"\n",
    " get topic context.py:\n",
    "     get topic ancestor titles and join these\n",
    "     ref: \n",
    "         https://www.kaggle.com/code/jamiealexandre/tips-and-recommendations-from-hosts/notebook\n",
    "     ex:\n",
    "         [grandparent topic title] + \" \" + [parent topic title] + \" \" + [topic title]\n",
    "\"\"\"\n",
    "\n",
    "# ================================================================\n",
    "#  Library\n",
    "# ================================================================\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "#  CFG\n",
    "# ================================================================\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--seed\", type=int, required=False,\n",
    "                       default=42)\n",
    "    parser.add_argument(\"--competition_dir\", type=str, required=False,\n",
    "                       default=\"/kaggle/input/learning-equality-curriculum-recommendations/\")\n",
    "    parser.add_argument(\"--output_dir\", type=str, required=False,\n",
    "                       default=\"/kaggle/working/get_topic_context/\")\n",
    "    parser.add_argument(\"--debug\", action=\"store_true\", required=False)\n",
    "    return parser.parse_args()\n",
    "\n",
    "CFG = parse_args()\n",
    "if not os.path.exists(CFG.output_dir):\n",
    "    os.makedirs(CFG.output_dir)\n",
    "for k, v in vars(CFG).items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "# ================================================================\n",
    "#  Utils\n",
    "# ================================================================\n",
    "def seed_everything(cfg):\n",
    "    os.environ['PYTHONHASHSEED'] = str(cfg.seed)\n",
    "    np.random.seed(cfg.seed)\n",
    "seed_everything(CFG)\n",
    "    \n",
    "# ================================================================\n",
    "#  DataLoading\n",
    "# ================================================================\n",
    "df_topics = pd.read_csv(CFG.competition_dir+\"topics.csv\").fillna({\"title\": \"\", \n",
    "                                                                  \"description\": \"\",\n",
    "                                                                  \"parent\": \"\"\n",
    "                                                                 })\n",
    "df_topics.rename(columns={\"id\":\"topic_id\"}, inplace=True)\n",
    "\n",
    "if CFG.debug:\n",
    "    sample_submission = df_topics.copy(deep=False).sample(n=10_000, random_state=CFG.seed)[[\"topic_id\"]]\n",
    "else:\n",
    "    sample_submission = pd.read_csv(CFG.competition_dir+\"sample_submission.csv\")\n",
    "sample_submission = pd.merge(sample_submission, df_topics[[\"topic_id\", \"channel\", \"title\", \"description\"]], \n",
    "                             on=\"topic_id\", how=\"left\")\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "#  get_context\n",
    "# ================================================================\n",
    "def get_ancestors(topic_id):\n",
    "    topic_title = df_topics[df_topics[\"topic_id\"] == topic_id][\"title\"].values[0]\n",
    "    topic_text = []\n",
    "    while True:\n",
    "        topic_text.append(topic_title)\n",
    "        parent_id = df_topics[df_topics[\"topic_id\"] == topic_id][\"parent\"].values[0]\n",
    "        if parent_id == \"\":\n",
    "            break\n",
    "        parent_title = df_topics[df_topics[\"topic_id\"] == parent_id][\"title\"].values[0]\n",
    "        topic_title = parent_title\n",
    "        topic_id = parent_id\n",
    "    topic_text.reverse()\n",
    "    return \"  \".join(topic_text)\n",
    "\n",
    "tqdm.pandas()\n",
    "sample_submission[\"context\"] = sample_submission[\"topic_id\"].progress_apply(get_ancestors)\n",
    "print(sample_submission.isnull().sum())\n",
    "sample_submission.to_csv(CFG.output_dir+\"topics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67e588bf",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-03-08T04:25:24.884146Z",
     "iopub.status.busy": "2023-03-08T04:25:24.883543Z",
     "iopub.status.idle": "2023-03-08T04:25:24.894807Z",
     "shell.execute_reply": "2023-03-08T04:25:24.893880Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.019174,
     "end_time": "2023-03-08T04:25:24.897369",
     "exception": false,
     "start_time": "2023-03-08T04:25:24.878195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 1st_stage_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 1st_stage_model.py\n",
    "\"\"\"\n",
    "1st_stage_model.py\n",
    "    retrive candidates from a lot of contents\n",
    "\"\"\"\n",
    "# ================================================================\n",
    "#  Library\n",
    "# ================================================================\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "import heapq\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import torch \n",
    "from torch import Tensor\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/kaggle/input/sentence-transformers/\")\n",
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device:\", device)\n",
    "\n",
    "# ================================================================\n",
    "#  args\n",
    "# ================================================================\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--seed\", type=int, required=False, \n",
    "                        default=42)\n",
    "    parser.add_argument(\"--competition_dir\", type=str, required=False,\n",
    "                        default=\"/kaggle/input/learning-equality-curriculum-recommendations/\")\n",
    "    parser.add_argument(\"--data_dir\", type=str, required=False,\n",
    "                        default=\"/kaggle/input/1st-stage-\")\n",
    "    parser.add_argument(\"--topic_dir\", type=str, required=False,\n",
    "                       default=\"/kaggle/working/get_topic_context/\")\n",
    "    parser.add_argument(\"--output_dir\", type=str, required=False,\n",
    "                        default=\"/kaggle/working/1st_stage_model/\")\n",
    "    parser.add_argument(\"--base_model\", type=str, required=False,\n",
    "                        default=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    parser.add_argument(\"--filename\", type=str,required=False, choices=[\"exp004\", \"exp006\", \"exp007\"],\n",
    "                        default=\"exp006\")\n",
    "    parser.add_argument(\"--max_len\", type=int, required=False,\n",
    "                       default=128)\n",
    "    parser.add_argument(\"--n_neighbors\", type=int, required=False,\n",
    "                       default=50)\n",
    "    parser.add_argument(\"--corpus_chunk_size\", type=int, required=False,\n",
    "                       default=40_000)\n",
    "    parser.add_argument(\"--batch_size\", type=int, required=False,\n",
    "                       default=96)\n",
    "    parser.add_argument(\"--n_fold\", type=int, required=False, nargs=\"*\",\n",
    "                       default=[0, 1, 2])\n",
    "    parser.add_argument(\"--debug\", action=\"store_true\", required=False)\n",
    "    args = parser.parse_args()\n",
    "        \n",
    "    args.data_dir = args.data_dir + f\"{args.filename}/\"\n",
    "    if not os.path.exists(args.output_dir):\n",
    "        os.makedirs(args.output_dir)    \n",
    "    return args\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "#  Utils\n",
    "# ================================================================\n",
    "def seed_everything(cfg):\n",
    "    \"\"\"set seed\"\"\"\n",
    "    random.seed(cfg.seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(cfg.seed)\n",
    "    np.random.seed(cfg.seed)\n",
    "    torch.manual_seed(cfg.seed)\n",
    "    torch.cuda.manual_seed(cfg.seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "\n",
    "def cos_sim(a: Tensor, b: Tensor):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\n",
    "    :return: Matrix with res[i][j]  = cos_sim(a[i], b[j])\n",
    "    \n",
    "    cited: https://github.com/UKPLab/sentence-transformers/blob/master/sentence_transformers/util.py\n",
    "    \"\"\"\n",
    "    if not isinstance(a, torch.Tensor):\n",
    "        a = torch.tensor(a)\n",
    "\n",
    "    if not isinstance(b, torch.Tensor):\n",
    "        b = torch.tensor(b)\n",
    "\n",
    "    if len(a.shape) == 1:\n",
    "        a = a.unsqueeze(0)\n",
    "\n",
    "    if len(b.shape) == 1:\n",
    "        b = b.unsqueeze(0)\n",
    "\n",
    "    a_norm = torch.nn.functional.normalize(a, p=2, dim=1)\n",
    "    b_norm = torch.nn.functional.normalize(b, p=2, dim=1)\n",
    "    return torch.mm(a_norm, b_norm.transpose(0, 1))\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "#  Data Loading\n",
    "# ================================================================\n",
    "def data_load(cfg):\n",
    "    print(\"========== Data Loading ==========\")\n",
    "    df_content = pd.read_csv(cfg.competition_dir+\"content.csv\").fillna({\"title\": \"\", \n",
    "                                                                        \"description\": \"\", \n",
    "                                                                        \"text\":\"\"})\n",
    "    if cfg.debug:\n",
    "        df_content = df_content.sample(n=100, random_state=cfg.seed).reset_index(drop=True)\n",
    "    \n",
    "    df_content.rename(columns={\"id\":\"content_id\"}, inplace=True)\n",
    "    df_topics = pd.read_csv(cfg.topic_dir+\"topics.csv\").fillna({\"title\": \"\", \n",
    "                                                                  \"description\": \"\",\n",
    "                                                                  \"parent\": \"\"\n",
    "                                                                 })\n",
    "    cfg.tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"/kaggle/input/1st-stage-exp006/fold0/sentence-transformers-all-mpnet-base-v2_fine-tuned\", \n",
    "        is_fast=True)\n",
    "            \n",
    "    df_content[\"sentence\"] = df_content[\"title\"] + cfg.tokenizer.sep_token + df_content[\"description\"]\n",
    "    df_topics[\"sentence\"] = df_topics[\"title\"] + cfg.tokenizer.sep_token +  df_topics[\"description\"] +\\\n",
    "    cfg.tokenizer.sep_token + df_topics[\"context\"]\n",
    "    \n",
    "    df_content[\"content_sentence\"] = df_content[\"sentence\"]\n",
    "    df_topics[\"topic_sentence\"] = df_topics[\"sentence\"]    \n",
    "    print(\"df_topics: \", df_topics.shape)\n",
    "    print(\"df_content: \", df_content.shape)\n",
    "    print(\"Input Sentence Example:\")\n",
    "    print(\"========== Topics ==========\")\n",
    "    print(df_topics[\"sentence\"].values.tolist()[:2])\n",
    "    print(\"========== Content ==========\")\n",
    "    print(df_content[\"sentence\"].values.tolist()[:2])\n",
    "    \n",
    "    print(df_topics.isnull().sum())\n",
    "\n",
    "    return df_content, df_topics\n",
    "\n",
    "\n",
    "def prepare_valid(df_content: pd.DataFrame, df_topics: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Create a query and corpus like the folloing.\n",
    "    \n",
    "    ex)\n",
    "    queries = {'q1': 'What is machine learning?',\n",
    "               'q2': 'How does deep learning work?'}\n",
    "    corpus = {'d1': 'Machine learning is a method of data analysis.', \n",
    "              'd2': 'Deep learning is a subfield of machine learning.', \n",
    "              'd3': 'Neural networks are used in deep learning.'}\n",
    "    \"\"\"\n",
    "    queries = df_topics[[\"topic_id\", \"topic_sentence\"]].set_index('topic_id').to_dict()['topic_sentence']\n",
    "    corpus = df_content[[\"content_id\", \"content_sentence\"]].set_index(\n",
    "                                                        'content_id').to_dict()['content_sentence']\n",
    "    return queries, corpus\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "#  Convert embeddings\n",
    "# ================================================================\n",
    "def FeatureExtractor(cfg):\n",
    "    \"\"\"model\"\"\"\n",
    "    word_embedding_model = models.Transformer(cfg.model, max_seq_length=cfg.max_len)\n",
    "    pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), \n",
    "                                   pooling_mode='mean')\n",
    "    model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "    return model\n",
    "\n",
    "def get_pair(cfg, queries: dict, corpus: dict, model, device):\n",
    "    \"\"\"\n",
    "    https://github.com/UKPLab/sentence-transformers/blob/master/sentence_transformers/evaluation/InformationRetrievalEvaluator.py\n",
    "    \"\"\"    \n",
    "    model.eval()\n",
    "    queries_ids = list(queries.keys())\n",
    "    queries = [queries[qid] for qid in queries_ids]\n",
    "\n",
    "    corpus_ids = list(corpus.keys())\n",
    "    corpus = [corpus[cid] for cid in corpus_ids]\n",
    "\n",
    "    query_embeddings = model.encode(queries,  \n",
    "                                    batch_size=cfg.batch_size, \n",
    "                                    convert_to_tensor=True)\n",
    "\n",
    "    queries_result_list = [[] for _ in range(len(query_embeddings))]\n",
    "\n",
    "    for corpus_start_idx in tqdm(range(0, len(corpus), cfg.corpus_chunk_size), desc=\"encode corpus & keep pairs\"):\n",
    "        corpus_end_idx = min(corpus_start_idx + cfg.corpus_chunk_size, len(corpus))\n",
    "\n",
    "        sub_corpus_embeddings = model.encode(corpus[corpus_start_idx:corpus_end_idx], \n",
    "                                             show_progress_bar=False, \n",
    "                                             batch_size=cfg.batch_size, \n",
    "                                             convert_to_tensor=True)\n",
    "\n",
    "        # Compute cosine similarites\n",
    "        pair_scores = cos_sim(query_embeddings, sub_corpus_embeddings)\n",
    "\n",
    "        # Get top-k values\n",
    "        pair_scores_top_k_values, pair_scores_top_k_idx = torch.topk(pair_scores, \n",
    "                                                                     min(cfg.n_neighbors, \n",
    "                                                                         len(pair_scores[0])), \n",
    "                                                                     dim=1, largest=True, sorted=False)\n",
    "        \n",
    "        pair_scores_top_k_values = pair_scores_top_k_values.cpu().tolist()\n",
    "        pair_scores_top_k_idx = pair_scores_top_k_idx.cpu().tolist()\n",
    "\n",
    "        for query_itr in range(len(query_embeddings)):\n",
    "            for sub_corpus_id, score in zip(pair_scores_top_k_idx[query_itr], pair_scores_top_k_values[query_itr]):\n",
    "                corpus_id = corpus_ids[corpus_start_idx+sub_corpus_id]\n",
    "                if len(queries_result_list[query_itr]) < cfg.n_neighbors:\n",
    "                    heapq.heappush(queries_result_list[query_itr], (score, corpus_id))  # heaqp tracks the quantity of the first element in the tuple\n",
    "                else:\n",
    "                    heapq.heappushpop(queries_result_list[query_itr], (score, corpus_id))\n",
    "\n",
    "    for query_itr in range(len(queries_result_list)):\n",
    "        for doc_itr in range(len(queries_result_list[query_itr])):\n",
    "            score, corpus_id = queries_result_list[query_itr][doc_itr]\n",
    "            queries_result_list[query_itr][doc_itr] = {'corpus_id': corpus_id, 'score': score}\n",
    "    return queries_ids, queries_result_list\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "#  save_pair\n",
    "# ================================================================\n",
    "def save_pair(cfg, fold, queries_ids: list, queries_result_list: list):\n",
    "    pair = {}\n",
    "    for query_itr in range(len(queries_result_list)):\n",
    "        query_id = queries_ids[query_itr]\n",
    "        # Sort scores\n",
    "        top_hits = sorted(queries_result_list[query_itr], key=lambda x: x['score'], reverse=True)\n",
    "        \n",
    "        corpus_id_list = {d['corpus_id'] for d in top_hits[0:cfg.n_neighbors]}\n",
    "        pair[query_id] = corpus_id_list\n",
    "\n",
    "    path = cfg.output_dir+f\"{cfg.filename}_fold{fold}_top{cfg.n_neighbors}.pkl\"\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(pair, f)\n",
    "    print(f\"{path} saved!\")\n",
    "    \n",
    "# ===============================================================\n",
    "#  main\n",
    "# ===============================================================\n",
    "def main(cfg):\n",
    "    seed_everything(cfg)\n",
    "    df_content, df_topics = data_load(cfg)\n",
    "    queries, corpus = prepare_valid(df_content, df_topics)   \n",
    "    \n",
    "    for fold in cfg.n_fold:        \n",
    "        # set model\n",
    "        cfg.model = cfg.data_dir+ f\"fold{fold}/\" + cfg.base_model.replace(\"/\", \"-\") + \"_fine-tuned/\"\n",
    "        print(cfg.model)\n",
    "        model = FeatureExtractor(cfg)\n",
    "        model.to(device)\n",
    "        # get_pair\n",
    "        queries_ids, queries_result_list = get_pair(cfg, queries, corpus, model, device)\n",
    "        # save\n",
    "        save_pair(cfg, fold, queries_ids, queries_result_list)\n",
    "        del model, queries_ids, queries_result_list\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        print('\\033[32m'+f\"{cfg.model} finish.\"+'\\033[0m')\n",
    "\n",
    "# ===============================================================\n",
    "#  Execute\n",
    "# ===============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    for k, v in vars(args).items():\n",
    "        print(f\"{k}: {v}\")\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80405e6a",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-03-08T04:25:24.908399Z",
     "iopub.status.busy": "2023-03-08T04:25:24.907726Z",
     "iopub.status.idle": "2023-03-08T04:25:24.920281Z",
     "shell.execute_reply": "2023-03-08T04:25:24.919421Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.019887,
     "end_time": "2023-03-08T04:25:24.922250",
     "exception": false,
     "start_time": "2023-03-08T04:25:24.902363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 2nd_stage_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 2nd_stage_model.py\n",
    "\n",
    "# ===============================================================\n",
    "#  Library\n",
    "# ===============================================================\n",
    "import os\n",
    "import gc\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import requests\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"device: {device}\")\n",
    "\n",
    "# ===============================================================\n",
    "#  args\n",
    "# ===============================================================\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--seed\", type=int, required=False, \n",
    "                        default=42)\n",
    "    parser.add_argument(\"--competition_dir\", type=str, required=False,\n",
    "                        default=\"/kaggle/input/learning-equality-curriculum-recommendations/\")\n",
    "    parser.add_argument(\"--data_dir\", type=str, required=False,\n",
    "                        default=\"/kaggle/input/2nd-stage-\")\n",
    "    parser.add_argument(\"--topic_dir\", type=str, required=False,\n",
    "                       default=\"/kaggle/working/1st_stage_model/\")\n",
    "    parser.add_argument(\"--output_dir\", type=str, required=False,\n",
    "                        default=\"/kaggle/working/2nd_stage_model/\")\n",
    "    parser.add_argument(\"--filename\", type=str, required=False, \n",
    "                        default=\"exp004\")    \n",
    "    parser.add_argument(\"--max_len\", type=int, required=False, \n",
    "                        default=256)    \n",
    "    parser.add_argument(\"--base_model\", type=str, required=False, \n",
    "                        default=\"sentence-transformers/all-MiniLM-L6-v2\")  \n",
    "    parser.add_argument(\"--batch_size\", type=int, required=False, \n",
    "                        default=64)    \n",
    "    parser.add_argument(\"--target_cols\", type=str, required=False, nargs=\"*\",\n",
    "                        default=[\"target\"])    \n",
    "    parser.add_argument(\"--n_fold\", type=int, required=False, nargs=\"*\",\n",
    "                        default=[0])    \n",
    "    parser.add_argument(\"--best_epoch\", type=int, required=False,\n",
    "                        default=3)    \n",
    "    args = parser.parse_args()\n",
    "    args.data_dir = args.data_dir + f\"{args.filename}/\"\n",
    "    if not os.path.exists(args.output_dir):\n",
    "        os.makedirs(args.output_dir)    \n",
    "    return args\n",
    "    \n",
    "# ===============================================================\n",
    "#  Utils\n",
    "# ===============================================================\n",
    "def seed_everything(cfg):\n",
    "    \"\"\"set seed\"\"\"\n",
    "    random.seed(cfg.seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(cfg.seed)\n",
    "    np.random.seed(cfg.seed)\n",
    "    torch.manual_seed(cfg.seed)\n",
    "    torch.cuda.manual_seed(cfg.seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "# ===============================================================\n",
    "#  tokenizer\n",
    "# ===============================================================\n",
    "def tokenizer(cfg):\n",
    "    cfg.tokenizer = AutoTokenizer.from_pretrained(\n",
    "        f'{cfg.data_dir}fold0/tokenizer',\n",
    "        is_fast=True)\n",
    "    return \n",
    "\n",
    "# ===============================================================\n",
    "#  DataLoading\n",
    "# ===============================================================\n",
    "def prepare_df(cfg, df_topics, df_content):\n",
    "    # load data\n",
    "    path = cfg.topic_dir+f\"exp006_fold0_top50.pkl\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        loaded_list = pickle.load(f)\n",
    "    df = pd.DataFrame.from_dict(loaded_list, orient='index').reset_index()\n",
    "    df.rename(columns={\"index\":\"topic_id\"}, inplace=True)\n",
    "    \n",
    "    # convert df for classification\n",
    "    df[\"predictions\"] = df.apply(\n",
    "    lambda x: \" \".join([str(val) for idx, val in enumerate(x) \\\n",
    "                        if pd.notna(val) and idx != df.columns.get_loc(\"topic_id\")]), axis=1\n",
    "    )\n",
    "    \n",
    "    df = df[[\"topic_id\", \"predictions\"]]\n",
    "    df = pd.merge(df, df_topics[[\"topic_id\", \"topic_sentence\", \"topic_length\"]], on=\"topic_id\", how=\"left\")\n",
    "    \n",
    "    df[\"predictions\"] = df[\"predictions\"].str.split()\n",
    "    df = df.explode(\"predictions\", ignore_index=True)\n",
    "    df = pd.merge(df, df_content[[\"id\", \"content_sentence\", \"content_length\"]].rename(columns={\"id\":\"predictions\"}),\n",
    "                  on=\"predictions\", how=\"left\")    \n",
    "    \n",
    "    # sort token \n",
    "    df[\"length\"] = df[\"topic_length\"] + df[\"content_length\"]\n",
    "    df.sort_values(by=\"length\", ascending=True, ignore_index=True, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def load_data(cfg):\n",
    "    df_topics = pd.read_csv(\"/kaggle/working/get_topic_context/topics.csv\").fillna({\"title\":\"\", \"description\":\"\"})\n",
    "    df_content = pd.read_csv(cfg.competition_dir+\"content.csv\").fillna(\n",
    "        {\"title\":\" \", \"description\":\"\", \"text\":\"\"})\n",
    "\n",
    "    # content sentence\n",
    "    df_content[\"content_sentence\"] = df_content[\"title\"] + cfg.tokenizer.sep_token + df_content[\"description\"]\n",
    "    print(df_content.isnull().sum())\n",
    "\n",
    "    # topic sentence\n",
    "    df_topics[\"topic_sentence\"] = df_topics[\"title\"] + cfg.tokenizer.sep_token +  df_topics[\"description\"] +\\\n",
    "    cfg.tokenizer.sep_token + df_topics[\"context\"]\n",
    "\n",
    "    df_topics[\"topic_sentence\"] = df_topics[\"topic_sentence\"].str.replace(\" >> \",  \" \")\n",
    "    \n",
    "    # encode sentence\n",
    "    df_content['content_length'] = [len(cfg.tokenizer(text)['input_ids']) \\\n",
    "                              for text in tqdm(df_content['content_sentence'].values, desc=\"encode content_sentence\")]\n",
    "    df_topics['topic_length'] = [len(cfg.tokenizer(text)['input_ids']) \\\n",
    "                             for text in tqdm(df_topics['topic_sentence'].values, desc=\"encode topic_sentence\")]\n",
    "    \n",
    "    df = prepare_df(cfg, df_topics, df_content)\n",
    "    print(\"df.shape: \", df.shape)\n",
    "    print(df.isnull().sum())\n",
    "    return df\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "#  Dataset\n",
    "# ===============================================================\n",
    "def prepare_input(cfg, text, text_pair):\n",
    "    inputs = cfg.tokenizer.encode_plus(\n",
    "        text, \n",
    "        text_pair,\n",
    "        return_tensors = None, \n",
    "        add_special_tokens = True, \n",
    "        max_length = cfg.max_len,\n",
    "        pad_to_max_length = True,\n",
    "        truncation = True\n",
    "    )\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype = torch.long)\n",
    "    return inputs\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.content_sentence = df[\"content_sentence\"].values\n",
    "        self.topic_sentence= df[\"topic_sentence\"].values\n",
    "    def __len__(self):\n",
    "        return len(self.topic_sentence)\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.cfg, self.topic_sentence[item], text_pair=self.content_sentence[item])\n",
    "        return inputs\n",
    "\n",
    "def collate(inputs):\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:,:mask_len]\n",
    "    return inputs\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "#  Model\n",
    "# ===============================================================\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "            self.config.hidden_dropout = 0\n",
    "            self.config.hidden_dropout_prob = 0\n",
    "            self.config.attention_dropout = 0\n",
    "            self.config.attetnion_probs_dropout_prob = 0\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel.from_config(self.config)\n",
    "        try:\n",
    "            self.model.gradient_checkpointing_enable()\n",
    "        except:\n",
    "            print(f'{cfg.base_model} does not support gradient checkpoint.')\n",
    "        self.pooler = MeanPooling()\n",
    "        self.fc = nn.Linear(self.config.hidden_size, len(cfg.target_cols))\n",
    "        self._init_weights(self.fc)\n",
    "        self.pooling = MeanPooling()\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.paddding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "            \n",
    "    def forward(self, inputs):\n",
    "        transformer_out = self.model(**inputs)\n",
    "        last_hidden_state = transformer_out.last_hidden_state\n",
    "        feature = self.pooling(last_hidden_state, inputs['attention_mask'])\n",
    "        output = self.fc(feature)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "# ===============================================================\n",
    "#  _loop_fn\n",
    "# ===============================================================\n",
    "def inference_fn(test_loader, model, device):\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    tk0 = tqdm(test_loader, total=len(test_loader))\n",
    "    for inputs in tk0:\n",
    "        inputs = collate(inputs)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        preds.append(y_preds.to('cpu').numpy())\n",
    "    predictions = np.concatenate(preds)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "#  loop_fn\n",
    "# ===============================================================\n",
    "def inference_loop(cfg, df, device):\n",
    "    df_dataset = TestDataset(cfg, df)\n",
    "    df_loader = DataLoader(df_dataset,\n",
    "                          batch_size=cfg.batch_size,\n",
    "                          shuffle=False,\n",
    "                          num_workers=0,\n",
    "                          pin_memory=True,\n",
    "                          drop_last=False)\n",
    "    \n",
    "    for fold in cfg.n_fold:\n",
    "        model = CustomModel(args, \n",
    "                            config_path=f'{cfg.data_dir}fold{fold}/'+'config.pth',\n",
    "                            pretrained=False)\n",
    "        state = torch.load(\n",
    "            f'{cfg.data_dir}fold{fold}/'+f\"{cfg.base_model.replace('/', '-')}_fold{fold}_epoch{cfg.best_epoch}_best.pth\",\n",
    "                        map_location=torch.device('cpu'))   \n",
    "        model.load_state_dict(state['model'])\n",
    "        prediction = inference_fn(df_loader, model, device)\n",
    "        torch.cuda.empty_cache()\n",
    "        df[\"target\"] = prediction\n",
    "        del model, state, prediction; gc.collect()\n",
    "        df.to_csv(f'{cfg.filename}_fold{fold}_submission.csv', index=False)\n",
    "        print('\\033[32m'+f\"{cfg.filename} fold{fold} finish.\"+'\\033[0m')\n",
    "\n",
    "    del df, df_dataset, df_loader\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "\n",
    "# ===============================================================\n",
    "#  main\n",
    "# ===============================================================\n",
    "def main(cfg):\n",
    "    seed_everything(cfg)\n",
    "    tokenizer(cfg)\n",
    "    df = load_data(cfg)    \n",
    "    inference_loop(cfg, df, device)\n",
    "                \n",
    "# ===============================================================\n",
    "#  Execution\n",
    "# ===============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    for k, v in vars(args).items():\n",
    "        print(f\"{k}: {v}\")\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54293d69",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-03-08T04:25:24.931986Z",
     "iopub.status.busy": "2023-03-08T04:25:24.931735Z",
     "iopub.status.idle": "2023-03-08T04:25:24.939048Z",
     "shell.execute_reply": "2023-03-08T04:25:24.938141Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.014874,
     "end_time": "2023-03-08T04:25:24.941304",
     "exception": false,
     "start_time": "2023-03-08T04:25:24.926430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing weighted_average.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile weighted_average.py\n",
    "\n",
    "# ================================================================\n",
    "#  Library\n",
    "# ================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "# ================================================================\n",
    "#  args\n",
    "# ================================================================\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--filenames\", type=str, required=False, nargs=\"*\", \n",
    "                       default=[\"exp004\", \"exp006\", \"exp007\", \"exp008\"])\n",
    "    parser.add_argument(\"--input_dir\", type=str, required=False, default=\"/kaggle/working/\")\n",
    "    parser.add_argument(\"--output_dir\", type=str, required=False, default=\"/kaggle/working/\")\n",
    "    parser.add_argument(\"--threshold\", type=float, required=False, default=0)\n",
    "    parser.add_argument(\"--weights\", type=float, required=False, nargs=\"*\",\n",
    "                        default=[0, 0, 0, 0])\n",
    "    parser.add_argument(\"--add_top\", type=int, required=False, default=0)\n",
    "    return parser.parse_args()\n",
    "\n",
    "# ================================================================\n",
    "#  Utils\n",
    "# ================================================================\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "#  DataLoading\n",
    "# ================================================================\n",
    "def load_data(cfg):\n",
    "    df = pd.DataFrame()\n",
    "    for i, filename in enumerate(cfg.filenames):\n",
    "        sub_df = pd.read_csv(cfg.input_dir+f\"{filename}_fold0_submission.csv\").rename(columns={\"predictions\":\"content_ids\", \n",
    "                                                                                               \"target\":f\"target_ver{i}\"})\n",
    "        if i == 0:\n",
    "            df = sub_df.copy(deep=False)\n",
    "        else:\n",
    "            df = pd.merge(df,\n",
    "                         sub_df[[\"topic_id\", \"content_ids\", f\"target_ver{i}\"]],\n",
    "                         on=[\"topic_id\", \"content_ids\"], how=\"left\")\n",
    "    return df\n",
    "\n",
    "# ================================================================\n",
    "#  Weighted average\n",
    "# ================================================================\n",
    "def weighted_average(cfg, df):\n",
    "    df[\"pred\"] = 0\n",
    "    for i, w in enumerate(cfg.weights):\n",
    "        df[\"pred\"] += df[f\"target_ver{i}\"] * w\n",
    "    df[\"sigmoid\"] = sigmoid(df[\"pred\"].values)\n",
    "    return df\n",
    "\n",
    "# ================================================================\n",
    "#  get submission\n",
    "# ================================================================\n",
    "def get_submission(cfg, df):\n",
    "    \n",
    "    # それぞれのトピックで確率が大きいコンテンツを取得する\n",
    "    top_df = df.groupby('topic_id').apply(lambda x: x.sort_values(by='pred', ascending=False\n",
    "                                                                 ).head(cfg.add_top)).reset_index(drop=True)\n",
    "    top_df = pd.DataFrame(top_df.groupby(\"topic_id\")[\"content_ids\"].agg(list)).reset_index()\n",
    "    top_df[\"content_ids\"] = top_df[\"content_ids\"].apply(lambda x: \" \".join(x))\n",
    "    \n",
    "    # 閾値より確率が大きいコンテンツを取得\n",
    "    df = df[df[\"sigmoid\"] > cfg.threshold].reset_index(drop=True)\n",
    "    df = df.groupby(\"topic_id\")[\"content_ids\"].agg(list).reset_index()\n",
    "    df[\"content_ids\"] = df[\"content_ids\"].apply(lambda x:\" \".join(x))\n",
    "    \n",
    "    # 各トピックに対して最低コンテンツを割り振るようにしたい\n",
    "    least_df = top_df[~top_df[\"topic_id\"].isin(df[\"topic_id\"].values)].reset_index(drop=True)\n",
    "    df = pd.concat([df, least_df], ignore_index=True)\n",
    "    \n",
    "    \n",
    "    df.to_csv(\"submission.csv\", index=False)\n",
    "    \n",
    "# ================================================================\n",
    "#  main\n",
    "# ================================================================\n",
    "def main(cfg):\n",
    "    df = load_data(cfg)\n",
    "    df = weighted_average(cfg, df)\n",
    "    get_submission(cfg, df)\n",
    "    \n",
    "\n",
    "# ================================================================\n",
    "#  execution\n",
    "# ================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    for k, v in vars(args).items():\n",
    "        print(f\"{k}: {v}\")\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aa17023",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T04:25:24.951521Z",
     "iopub.status.busy": "2023-03-08T04:25:24.950682Z",
     "iopub.status.idle": "2023-03-08T04:25:27.185039Z",
     "shell.execute_reply": "2023-03-08T04:25:27.183712Z"
    },
    "papermill": {
     "duration": 2.242089,
     "end_time": "2023-03-08T04:25:27.187704",
     "exception": false,
     "start_time": "2023-03-08T04:25:24.945615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "seed: 42\r\n",
      "competition_dir: /kaggle/input/learning-equality-curriculum-recommendations/\r\n",
      "output_dir: /kaggle/working/get_topic_context/\r\n",
      "debug: False\r\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:00<00:00, 32.85it/s]\r\n",
      "topic_id       0\r\n",
      "content_ids    0\r\n",
      "channel        0\r\n",
      "title          0\r\n",
      "description    0\r\n",
      "context        0\r\n",
      "dtype: int64\r\n"
     ]
    }
   ],
   "source": [
    "!python get_topic_context.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9f3871d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T04:25:27.198992Z",
     "iopub.status.busy": "2023-03-08T04:25:27.198604Z",
     "iopub.status.idle": "2023-03-08T04:31:26.584253Z",
     "shell.execute_reply": "2023-03-08T04:31:26.583064Z"
    },
    "papermill": {
     "duration": 359.394453,
     "end_time": "2023-03-08T04:31:26.587110",
     "exception": false,
     "start_time": "2023-03-08T04:25:27.192657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "device: cuda\r\n",
      "seed: 42\r\n",
      "competition_dir: /kaggle/input/learning-equality-curriculum-recommendations/\r\n",
      "data_dir: /kaggle/input/1st-stage-exp006/\r\n",
      "topic_dir: /kaggle/working/get_topic_context/\r\n",
      "output_dir: /kaggle/working/1st_stage_model/\r\n",
      "base_model: sentence-transformers/all-mpnet-base-v2\r\n",
      "filename: exp006\r\n",
      "max_len: 128\r\n",
      "n_neighbors: 50\r\n",
      "corpus_chunk_size: 40000\r\n",
      "batch_size: 96\r\n",
      "n_fold: [0]\r\n",
      "debug: False\r\n",
      "========== Data Loading ==========\r\n",
      "df_topics:  (5, 8)\r\n",
      "df_content:  (154047, 10)\r\n",
      "Input Sentence Example:\r\n",
      "========== Topics ==========\r\n",
      "['Откриването на резисторите</s>Изследване на материали, които предизвикват намаление в отклонението, когато се свържат последователно с нашия измервателен уред. </s>Khan Academy (български език)  Наука  Физика  Открития и проекти  Откриването на резисторите', 'Entradas e saídas de uma função</s>Entenda um pouco mais sobre funções.</s>Khan Academy (Português (Brasil))  Matemática por ano (Alinhada à BNCC)  9º Ano  Álgebra: funções  Entradas e saídas de uma função']\r\n",
      "========== Content ==========\r\n",
      "['Sumar números de varios dígitos: 48,029+233,930 </s>Suma 48,029+233,930 mediante el algoritmo estándar.\\n\\n', 'Trovare i fattori di un numero</s>Sal trova i fattori di 120.\\n\\n']\r\n",
      "topic_id          0\r\n",
      "content_ids       0\r\n",
      "channel           0\r\n",
      "title             0\r\n",
      "description       0\r\n",
      "context           0\r\n",
      "sentence          0\r\n",
      "topic_sentence    0\r\n",
      "dtype: int64\r\n",
      "/kaggle/input/1st-stage-exp006/fold0/sentence-transformers-all-mpnet-base-v2_fine-tuned/\r\n",
      "Batches: 100%|████████████████████████████████████| 1/1 [00:01<00:00,  1.81s/it]\r\n",
      "encode corpus & keep pairs: 100%|█████████████████| 4/4 [05:21<00:00, 80.43s/it]\r\n",
      "/kaggle/working/1st_stage_model/exp006_fold0_top50.pkl saved!\r\n",
      "\u001b[32m/kaggle/input/1st-stage-exp006/fold0/sentence-transformers-all-mpnet-base-v2_fine-tuned/ finish.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python 1st_stage_model.py\\\n",
    "--n_neighbors 50\\\n",
    "--n_fold 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "700b5abf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T04:31:26.599978Z",
     "iopub.status.busy": "2023-03-08T04:31:26.599039Z",
     "iopub.status.idle": "2023-03-08T04:32:14.010606Z",
     "shell.execute_reply": "2023-03-08T04:32:14.009327Z"
    },
    "papermill": {
     "duration": 47.420531,
     "end_time": "2023-03-08T04:32:14.013187",
     "exception": false,
     "start_time": "2023-03-08T04:31:26.592656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "device: cuda\r\n",
      "seed: 42\r\n",
      "competition_dir: /kaggle/input/learning-equality-curriculum-recommendations/\r\n",
      "data_dir: /kaggle/input/2nd-stage-exp004/\r\n",
      "topic_dir: /kaggle/working/1st_stage_model/\r\n",
      "output_dir: /kaggle/working/2nd_stage_model/\r\n",
      "filename: exp004\r\n",
      "max_len: 256\r\n",
      "base_model: sentence-transformers/all-MiniLM-L6-v2\r\n",
      "batch_size: 64\r\n",
      "target_cols: ['target']\r\n",
      "n_fold: [0]\r\n",
      "best_epoch: 3\r\n",
      "id                      0\r\n",
      "title                   0\r\n",
      "description             0\r\n",
      "kind                    0\r\n",
      "text                    0\r\n",
      "language                0\r\n",
      "copyright_holder    82226\r\n",
      "license             80012\r\n",
      "content_sentence        0\r\n",
      "dtype: int64\r\n",
      "encode content_sentence: 100%|████████| 154047/154047 [00:28<00:00, 5482.64it/s]\r\n",
      "encode topic_sentence: 100%|████████████████████| 5/5 [00:00<00:00, 1407.58it/s]\r\n",
      "df.shape:  (250, 7)\r\n",
      "topic_id            0\r\n",
      "predictions         0\r\n",
      "topic_sentence      0\r\n",
      "topic_length        0\r\n",
      "content_sentence    0\r\n",
      "content_length      0\r\n",
      "length              0\r\n",
      "dtype: int64\r\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:00<00:00,  4.83it/s]\r\n",
      "\u001b[32mexp004 fold0 finish.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python 2nd_stage_model.py\\\n",
    "--filename exp004\\\n",
    "--base_model sentence-transformers/all-MiniLM-L6-v2\\\n",
    "--best_epoch 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6672d0f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T04:32:14.054022Z",
     "iopub.status.busy": "2023-03-08T04:32:14.053685Z",
     "iopub.status.idle": "2023-03-08T04:33:05.997202Z",
     "shell.execute_reply": "2023-03-08T04:33:05.996041Z"
    },
    "papermill": {
     "duration": 51.967088,
     "end_time": "2023-03-08T04:33:06.000121",
     "exception": false,
     "start_time": "2023-03-08T04:32:14.033033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "device: cuda\r\n",
      "seed: 42\r\n",
      "competition_dir: /kaggle/input/learning-equality-curriculum-recommendations/\r\n",
      "data_dir: /kaggle/input/2nd-stage-exp006/\r\n",
      "topic_dir: /kaggle/working/1st_stage_model/\r\n",
      "output_dir: /kaggle/working/2nd_stage_model/\r\n",
      "filename: exp006\r\n",
      "max_len: 256\r\n",
      "base_model: sentence-transformers/all-mpnet-base-v2\r\n",
      "batch_size: 64\r\n",
      "target_cols: ['target']\r\n",
      "n_fold: [0]\r\n",
      "best_epoch: 3\r\n",
      "id                      0\r\n",
      "title                   0\r\n",
      "description             0\r\n",
      "kind                    0\r\n",
      "text                    0\r\n",
      "language                0\r\n",
      "copyright_holder    82226\r\n",
      "license             80012\r\n",
      "content_sentence        0\r\n",
      "dtype: int64\r\n",
      "encode content_sentence: 100%|████████| 154047/154047 [00:27<00:00, 5703.74it/s]\r\n",
      "encode topic_sentence: 100%|████████████████████| 5/5 [00:00<00:00, 1233.76it/s]\r\n",
      "df.shape:  (250, 7)\r\n",
      "topic_id            0\r\n",
      "predictions         0\r\n",
      "topic_sentence      0\r\n",
      "topic_length        0\r\n",
      "content_sentence    0\r\n",
      "content_length      0\r\n",
      "length              0\r\n",
      "dtype: int64\r\n",
      "sentence-transformers/all-mpnet-base-v2 does not support gradient checkpoint.\r\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:02<00:00,  1.93it/s]\r\n",
      "\u001b[32mexp006 fold0 finish.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python 2nd_stage_model.py\\\n",
    "--filename exp006\\\n",
    "--base_model sentence-transformers/all-mpnet-base-v2\\\n",
    "--best_epoch 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ec90d7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T04:33:06.068303Z",
     "iopub.status.busy": "2023-03-08T04:33:06.067975Z",
     "iopub.status.idle": "2023-03-08T04:34:08.051267Z",
     "shell.execute_reply": "2023-03-08T04:34:08.050034Z"
    },
    "papermill": {
     "duration": 62.019617,
     "end_time": "2023-03-08T04:34:08.053845",
     "exception": false,
     "start_time": "2023-03-08T04:33:06.034228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "device: cuda\r\n",
      "seed: 42\r\n",
      "competition_dir: /kaggle/input/learning-equality-curriculum-recommendations/\r\n",
      "data_dir: /kaggle/input/2nd-stage-exp007/\r\n",
      "topic_dir: /kaggle/working/1st_stage_model/\r\n",
      "output_dir: /kaggle/working/2nd_stage_model/\r\n",
      "filename: exp007\r\n",
      "max_len: 256\r\n",
      "base_model: xlm-roberta-base\r\n",
      "batch_size: 64\r\n",
      "target_cols: ['target']\r\n",
      "n_fold: [0]\r\n",
      "best_epoch: 3\r\n",
      "id                      0\r\n",
      "title                   0\r\n",
      "description             0\r\n",
      "kind                    0\r\n",
      "text                    0\r\n",
      "language                0\r\n",
      "copyright_holder    82226\r\n",
      "license             80012\r\n",
      "content_sentence        0\r\n",
      "dtype: int64\r\n",
      "encode content_sentence: 100%|████████| 154047/154047 [00:27<00:00, 5580.27it/s]\r\n",
      "encode topic_sentence: 100%|████████████████████| 5/5 [00:00<00:00, 1199.19it/s]\r\n",
      "df.shape:  (250, 7)\r\n",
      "topic_id            0\r\n",
      "predictions         0\r\n",
      "topic_sentence      0\r\n",
      "topic_length        0\r\n",
      "content_sentence    0\r\n",
      "content_length      0\r\n",
      "length              0\r\n",
      "dtype: int64\r\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  2.39it/s]\r\n",
      "\u001b[32mexp007 fold0 finish.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python 2nd_stage_model.py\\\n",
    "--filename exp007\\\n",
    "--base_model xlm-roberta-base\\\n",
    "--best_epoch 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4958ec7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T04:34:08.150098Z",
     "iopub.status.busy": "2023-03-08T04:34:08.149079Z",
     "iopub.status.idle": "2023-03-08T04:35:07.855723Z",
     "shell.execute_reply": "2023-03-08T04:35:07.854496Z"
    },
    "papermill": {
     "duration": 59.757249,
     "end_time": "2023-03-08T04:35:07.858436",
     "exception": false,
     "start_time": "2023-03-08T04:34:08.101187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "device: cuda\r\n",
      "seed: 42\r\n",
      "competition_dir: /kaggle/input/learning-equality-curriculum-recommendations/\r\n",
      "data_dir: /kaggle/input/2nd-stage-exp008/\r\n",
      "topic_dir: /kaggle/working/1st_stage_model/\r\n",
      "output_dir: /kaggle/working/2nd_stage_model/\r\n",
      "filename: exp008\r\n",
      "max_len: 256\r\n",
      "base_model: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\r\n",
      "batch_size: 64\r\n",
      "target_cols: ['target']\r\n",
      "n_fold: [0]\r\n",
      "best_epoch: 2\r\n",
      "id                      0\r\n",
      "title                   0\r\n",
      "description             0\r\n",
      "kind                    0\r\n",
      "text                    0\r\n",
      "language                0\r\n",
      "copyright_holder    82226\r\n",
      "license             80012\r\n",
      "content_sentence        0\r\n",
      "dtype: int64\r\n",
      "encode content_sentence: 100%|████████| 154047/154047 [00:27<00:00, 5566.00it/s]\r\n",
      "encode topic_sentence: 100%|████████████████████| 5/5 [00:00<00:00, 1036.40it/s]\r\n",
      "df.shape:  (250, 7)\r\n",
      "topic_id            0\r\n",
      "predictions         0\r\n",
      "topic_sentence      0\r\n",
      "topic_length        0\r\n",
      "content_sentence    0\r\n",
      "content_length      0\r\n",
      "length              0\r\n",
      "dtype: int64\r\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  2.49it/s]\r\n",
      "\u001b[32mexp008 fold0 finish.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python 2nd_stage_model.py\\\n",
    "--filename exp008\\\n",
    "--base_model sentence-transformers/paraphrase-multilingual-mpnet-base-v2\\\n",
    "--best_epoch 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2329c65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T04:35:07.985254Z",
     "iopub.status.busy": "2023-03-08T04:35:07.984258Z",
     "iopub.status.idle": "2023-03-08T04:35:09.482607Z",
     "shell.execute_reply": "2023-03-08T04:35:09.481419Z"
    },
    "papermill": {
     "duration": 1.562727,
     "end_time": "2023-03-08T04:35:09.485129",
     "exception": false,
     "start_time": "2023-03-08T04:35:07.922402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "filenames: ['exp004', 'exp006', 'exp007', 'exp008']\r\n",
      "input_dir: /kaggle/working/\r\n",
      "output_dir: /kaggle/working/\r\n",
      "threshold: 0.064\r\n",
      "weights: [0.062227624496708774, 0.13089890735166354, 0.12593408621879854, 0.09816979516903653]\r\n",
      "add_top: 9\r\n"
     ]
    }
   ],
   "source": [
    "!python weighted_average.py\\\n",
    "--filenames exp004 exp006 exp007 exp008\\\n",
    "--threshold 0.064\\\n",
    "--weights 0.062227624496708774 0.13089890735166354 0.12593408621879854 0.09816979516903653\\\n",
    "--add_top 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae32b646",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T04:35:09.610245Z",
     "iopub.status.busy": "2023-03-08T04:35:09.609907Z",
     "iopub.status.idle": "2023-03-08T04:35:09.630414Z",
     "shell.execute_reply": "2023-03-08T04:35:09.629535Z"
    },
    "papermill": {
     "duration": 0.086174,
     "end_time": "2023-03-08T04:35:09.632353",
     "exception": false,
     "start_time": "2023-03-08T04:35:09.546179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>content_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_dfa229bd21df c_1108dd0c7a5d c_e1e8557d7c61 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_00068291e9a4</td>\n",
       "      <td>c_639ea2ef9c95 c_ebb7fdf10a7e c_c8bcd26a5f3e c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_00069b63a70a</td>\n",
       "      <td>c_11a1dc0bfb99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_0006d41a73a8</td>\n",
       "      <td>c_b972646631cb c_0c6473c3480d c_d7a0d7eaf799 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_4054df11a74e</td>\n",
       "      <td>c_3695c5dc1df6 c_f2d184a98231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic_id                                        content_ids\n",
       "0  t_00004da3a1b2  c_dfa229bd21df c_1108dd0c7a5d c_e1e8557d7c61 c...\n",
       "1  t_00068291e9a4  c_639ea2ef9c95 c_ebb7fdf10a7e c_c8bcd26a5f3e c...\n",
       "2  t_00069b63a70a                                     c_11a1dc0bfb99\n",
       "3  t_0006d41a73a8  c_b972646631cb c_0c6473c3480d c_d7a0d7eaf799 c...\n",
       "4  t_4054df11a74e                      c_3695c5dc1df6 c_f2d184a98231"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1a5e4b",
   "metadata": {
    "papermill": {
     "duration": 0.060652,
     "end_time": "2023-03-08T04:35:09.754767",
     "exception": false,
     "start_time": "2023-03-08T04:35:09.694115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 593.237895,
   "end_time": "2023-03-08T04:35:10.335723",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-08T04:25:17.097828",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
