{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6984377",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-03-13T07:20:39.632530Z",
     "iopub.status.busy": "2023-03-13T07:20:39.631978Z",
     "iopub.status.idle": "2023-03-13T07:20:39.644107Z",
     "shell.execute_reply": "2023-03-13T07:20:39.643102Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.023751,
     "end_time": "2023-03-13T07:20:39.648303",
     "exception": false,
     "start_time": "2023-03-13T07:20:39.624552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "%env TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9ec0333",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-03-13T07:20:39.658279Z",
     "iopub.status.busy": "2023-03-13T07:20:39.657989Z",
     "iopub.status.idle": "2023-03-13T07:20:39.666169Z",
     "shell.execute_reply": "2023-03-13T07:20:39.664936Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.015376,
     "end_time": "2023-03-13T07:20:39.668150",
     "exception": false,
     "start_time": "2023-03-13T07:20:39.652774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing get_topic_context.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile get_topic_context.py\n",
    "\"\"\"\n",
    " get topic context.py:\n",
    "     get topic ancestor titles and join these\n",
    "     ref: \n",
    "         https://www.kaggle.com/code/jamiealexandre/tips-and-recommendations-from-hosts/notebook\n",
    "     ex:\n",
    "         [grandparent topic title] + \" \" + [parent topic title] + \" \" + [topic title]\n",
    "\"\"\"\n",
    "\n",
    "# ================================================================\n",
    "#  Library\n",
    "# ================================================================\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "#  CFG\n",
    "# ================================================================\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--seed\", type=int, required=False,\n",
    "                       default=42)\n",
    "    parser.add_argument(\"--competition_dir\", type=str, required=False,\n",
    "                       default=\"/kaggle/input/learning-equality-curriculum-recommendations/\")\n",
    "    parser.add_argument(\"--output_dir\", type=str, required=False,\n",
    "                       default=\"/kaggle/working/get_topic_context/\")\n",
    "    parser.add_argument(\"--debug\", action=\"store_true\", required=False)\n",
    "    return parser.parse_args()\n",
    "\n",
    "CFG = parse_args()\n",
    "if not os.path.exists(CFG.output_dir):\n",
    "    os.makedirs(CFG.output_dir)\n",
    "for k, v in vars(CFG).items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "# ================================================================\n",
    "#  Utils\n",
    "# ================================================================\n",
    "def seed_everything(cfg):\n",
    "    os.environ['PYTHONHASHSEED'] = str(cfg.seed)\n",
    "    np.random.seed(cfg.seed)\n",
    "seed_everything(CFG)\n",
    "    \n",
    "# ================================================================\n",
    "#  DataLoading\n",
    "# ================================================================\n",
    "df_topics = pd.read_csv(CFG.competition_dir+\"topics.csv\").fillna({\"title\": \"\", \n",
    "                                                                  \"description\": \"\",\n",
    "                                                                  \"parent\": \"\"\n",
    "                                                                 })\n",
    "df_topics.rename(columns={\"id\":\"topic_id\"}, inplace=True)\n",
    "\n",
    "if CFG.debug:\n",
    "    sample_submission = df_topics.copy(deep=False).sample(n=10_000, random_state=CFG.seed)[[\"topic_id\"]]\n",
    "else:\n",
    "    sample_submission = pd.read_csv(CFG.competition_dir+\"sample_submission.csv\")\n",
    "sample_submission = pd.merge(sample_submission, df_topics[[\"topic_id\", \"channel\", \"title\", \"description\"]], \n",
    "                             on=\"topic_id\", how=\"left\")\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "#  get_context\n",
    "# ================================================================\n",
    "def get_ancestors(topic_id):\n",
    "    topic_title = df_topics[df_topics[\"topic_id\"] == topic_id][\"title\"].values[0]\n",
    "    topic_text = []\n",
    "    while True:\n",
    "        topic_text.append(topic_title)\n",
    "        parent_id = df_topics[df_topics[\"topic_id\"] == topic_id][\"parent\"].values[0]\n",
    "        if parent_id == \"\":\n",
    "            break\n",
    "        parent_title = df_topics[df_topics[\"topic_id\"] == parent_id][\"title\"].values[0]\n",
    "        topic_title = parent_title\n",
    "        topic_id = parent_id\n",
    "    topic_text.reverse()\n",
    "    return \"  \".join(topic_text)\n",
    "\n",
    "tqdm.pandas()\n",
    "sample_submission[\"context\"] = sample_submission[\"topic_id\"].progress_apply(get_ancestors)\n",
    "print(sample_submission.isnull().sum())\n",
    "print(sample_submission[\"context\"].values[:2])\n",
    "sample_submission.to_csv(CFG.output_dir+\"topics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85934e0d",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-03-13T07:20:39.679014Z",
     "iopub.status.busy": "2023-03-13T07:20:39.678095Z",
     "iopub.status.idle": "2023-03-13T07:20:39.689993Z",
     "shell.execute_reply": "2023-03-13T07:20:39.688899Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.019652,
     "end_time": "2023-03-13T07:20:39.692055",
     "exception": false,
     "start_time": "2023-03-13T07:20:39.672403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 1st_stage_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 1st_stage_model.py\n",
    "\"\"\"\n",
    "1st_stage_model.py\n",
    "    retrive candidates from a lot of contents\n",
    "\"\"\"\n",
    "# ================================================================\n",
    "#  Library\n",
    "# ================================================================\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "import heapq\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import torch \n",
    "from torch import Tensor\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/kaggle/input/sentence-transformers/\")\n",
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device:\", device)\n",
    "\n",
    "# ================================================================\n",
    "#  args\n",
    "# ================================================================\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--seed\", type=int, required=False, \n",
    "                        default=42)\n",
    "    parser.add_argument(\"--competition_dir\", type=str, required=False,\n",
    "                        default=\"/kaggle/input/learning-equality-curriculum-recommendations/\")\n",
    "    parser.add_argument(\"--data_dir\", type=str, required=False,\n",
    "                        default=\"/kaggle/input/1st-stage-\")\n",
    "    parser.add_argument(\"--topic_dir\", type=str, required=False,\n",
    "                       default=\"/kaggle/working/get_topic_context/\")\n",
    "    parser.add_argument(\"--output_dir\", type=str, required=False,\n",
    "                        default=\"/kaggle/working/1st_stage_model/\")\n",
    "    parser.add_argument(\"--base_model\", type=str, required=False,\n",
    "                        default=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    parser.add_argument(\"--filename\", type=str,required=False, choices=[\"exp004\", \"exp006\", \"exp007\"],\n",
    "                        default=\"exp006\")\n",
    "    parser.add_argument(\"--max_len\", type=int, required=False,\n",
    "                       default=128)\n",
    "    parser.add_argument(\"--n_neighbors\", type=int, required=False,\n",
    "                       default=50)\n",
    "    parser.add_argument(\"--corpus_chunk_size\", type=int, required=False,\n",
    "                       default=40_000)\n",
    "    parser.add_argument(\"--batch_size\", type=int, required=False,\n",
    "                       default=96)\n",
    "    parser.add_argument(\"--n_fold\", type=int, required=False, nargs=\"*\",\n",
    "                       default=[0, 1, 2])\n",
    "    parser.add_argument(\"--debug\", action=\"store_true\", required=False)\n",
    "    args = parser.parse_args()\n",
    "        \n",
    "    args.data_dir = args.data_dir + f\"{args.filename}/\"\n",
    "    if not os.path.exists(args.output_dir):\n",
    "        os.makedirs(args.output_dir)    \n",
    "    return args\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "#  Utils\n",
    "# ================================================================\n",
    "def seed_everything(cfg):\n",
    "    \"\"\"set seed\"\"\"\n",
    "    random.seed(cfg.seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(cfg.seed)\n",
    "    np.random.seed(cfg.seed)\n",
    "    torch.manual_seed(cfg.seed)\n",
    "    torch.cuda.manual_seed(cfg.seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "\n",
    "def cos_sim(a: Tensor, b: Tensor):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\n",
    "    :return: Matrix with res[i][j]  = cos_sim(a[i], b[j])\n",
    "    \n",
    "    cited: https://github.com/UKPLab/sentence-transformers/blob/master/sentence_transformers/util.py\n",
    "    \"\"\"\n",
    "    if not isinstance(a, torch.Tensor):\n",
    "        a = torch.tensor(a)\n",
    "\n",
    "    if not isinstance(b, torch.Tensor):\n",
    "        b = torch.tensor(b)\n",
    "\n",
    "    if len(a.shape) == 1:\n",
    "        a = a.unsqueeze(0)\n",
    "\n",
    "    if len(b.shape) == 1:\n",
    "        b = b.unsqueeze(0)\n",
    "\n",
    "    a_norm = torch.nn.functional.normalize(a, p=2, dim=1)\n",
    "    b_norm = torch.nn.functional.normalize(b, p=2, dim=1)\n",
    "    return torch.mm(a_norm, b_norm.transpose(0, 1))\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "#  Data Loading\n",
    "# ================================================================\n",
    "def data_load(cfg):\n",
    "    print(\"========== Data Loading ==========\")\n",
    "    df_content = pd.read_csv(cfg.competition_dir+\"content.csv\").fillna({\"title\": \"\", \n",
    "                                                                        \"description\": \"\", \n",
    "                                                                        \"text\":\"\"})\n",
    "    if cfg.debug:\n",
    "        df_content = df_content.sample(n=100, random_state=cfg.seed).reset_index(drop=True)\n",
    "    \n",
    "    df_content.rename(columns={\"id\":\"content_id\"}, inplace=True)\n",
    "    df_topics = pd.read_csv(cfg.topic_dir+\"topics.csv\").fillna({\"title\": \"\", \n",
    "                                                                  \"description\": \"\",\n",
    "                                                                  \"parent\": \"\"\n",
    "                                                                 })\n",
    "    cfg.tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"/kaggle/input/1st-stage-exp006/fold0/sentence-transformers-all-mpnet-base-v2_fine-tuned\", \n",
    "        is_fast=True)\n",
    "            \n",
    "    df_content[\"sentence\"] = df_content[\"title\"] + cfg.tokenizer.sep_token + df_content[\"description\"]\n",
    "    df_topics[\"sentence\"] = df_topics[\"title\"] + cfg.tokenizer.sep_token +  df_topics[\"description\"] +\\\n",
    "    cfg.tokenizer.sep_token + df_topics[\"context\"]\n",
    "    \n",
    "    df_content[\"content_sentence\"] = df_content[\"sentence\"]\n",
    "    df_topics[\"topic_sentence\"] = df_topics[\"sentence\"]    \n",
    "    print(\"df_topics: \", df_topics.shape)\n",
    "    print(\"df_content: \", df_content.shape)\n",
    "    print(\"Input Sentence Example:\")\n",
    "    print(\"========== Topics ==========\")\n",
    "    print(df_topics[\"sentence\"].values.tolist()[:2])\n",
    "    print(\"========== Content ==========\")\n",
    "    print(df_content[\"sentence\"].values.tolist()[:2])\n",
    "    \n",
    "    print(df_topics.isnull().sum())\n",
    "\n",
    "    return df_content, df_topics\n",
    "\n",
    "\n",
    "def prepare_valid(df_content: pd.DataFrame, df_topics: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Create a query and corpus like the folloing.\n",
    "    \n",
    "    ex)\n",
    "    queries = {'q1': 'What is machine learning?',\n",
    "               'q2': 'How does deep learning work?'}\n",
    "    corpus = {'d1': 'Machine learning is a method of data analysis.', \n",
    "              'd2': 'Deep learning is a subfield of machine learning.', \n",
    "              'd3': 'Neural networks are used in deep learning.'}\n",
    "    \"\"\"\n",
    "    queries = df_topics[[\"topic_id\", \"topic_sentence\"]].set_index('topic_id').to_dict()['topic_sentence']\n",
    "    corpus = df_content[[\"content_id\", \"content_sentence\"]].set_index(\n",
    "                                                        'content_id').to_dict()['content_sentence']\n",
    "    return queries, corpus\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "#  Convert embeddings\n",
    "# ================================================================\n",
    "def FeatureExtractor(cfg):\n",
    "    \"\"\"model\"\"\"\n",
    "    word_embedding_model = models.Transformer(cfg.model, max_seq_length=cfg.max_len)\n",
    "    pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), \n",
    "                                   pooling_mode='mean')\n",
    "    model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "    return model\n",
    "\n",
    "def get_pair(cfg, queries: dict, corpus: dict, model, device):\n",
    "    \"\"\"\n",
    "    https://github.com/UKPLab/sentence-transformers/blob/master/sentence_transformers/evaluation/InformationRetrievalEvaluator.py\n",
    "    \"\"\"    \n",
    "    model.eval()\n",
    "    queries_ids = list(queries.keys())\n",
    "    queries = [queries[qid] for qid in queries_ids]\n",
    "\n",
    "    corpus_ids = list(corpus.keys())\n",
    "    corpus = [corpus[cid] for cid in corpus_ids]\n",
    "\n",
    "    query_embeddings = model.encode(queries,  \n",
    "                                    batch_size=cfg.batch_size, \n",
    "                                    convert_to_tensor=True)\n",
    "\n",
    "    queries_result_list = [[] for _ in range(len(query_embeddings))]\n",
    "\n",
    "    for corpus_start_idx in tqdm(range(0, len(corpus), cfg.corpus_chunk_size), desc=\"encode corpus & keep pairs\"):\n",
    "        corpus_end_idx = min(corpus_start_idx + cfg.corpus_chunk_size, len(corpus))\n",
    "\n",
    "        sub_corpus_embeddings = model.encode(corpus[corpus_start_idx:corpus_end_idx], \n",
    "                                             show_progress_bar=False, \n",
    "                                             batch_size=cfg.batch_size, \n",
    "                                             convert_to_tensor=True)\n",
    "\n",
    "        # Compute cosine similarites\n",
    "        pair_scores = cos_sim(query_embeddings, sub_corpus_embeddings)\n",
    "\n",
    "        # Get top-k values\n",
    "        pair_scores_top_k_values, pair_scores_top_k_idx = torch.topk(pair_scores, \n",
    "                                                                     min(cfg.n_neighbors, \n",
    "                                                                         len(pair_scores[0])), \n",
    "                                                                     dim=1, largest=True, sorted=False)\n",
    "        \n",
    "        pair_scores_top_k_values = pair_scores_top_k_values.cpu().tolist()\n",
    "        pair_scores_top_k_idx = pair_scores_top_k_idx.cpu().tolist()\n",
    "\n",
    "        for query_itr in range(len(query_embeddings)):\n",
    "            for sub_corpus_id, score in zip(pair_scores_top_k_idx[query_itr], pair_scores_top_k_values[query_itr]):\n",
    "                corpus_id = corpus_ids[corpus_start_idx+sub_corpus_id]\n",
    "                if len(queries_result_list[query_itr]) < cfg.n_neighbors:\n",
    "                    heapq.heappush(queries_result_list[query_itr], (score, corpus_id))  # heaqp tracks the quantity of the first element in the tuple\n",
    "                else:\n",
    "                    heapq.heappushpop(queries_result_list[query_itr], (score, corpus_id))\n",
    "\n",
    "    for query_itr in range(len(queries_result_list)):\n",
    "        for doc_itr in range(len(queries_result_list[query_itr])):\n",
    "            score, corpus_id = queries_result_list[query_itr][doc_itr]\n",
    "            queries_result_list[query_itr][doc_itr] = {'corpus_id': corpus_id, 'score': score}\n",
    "    return queries_ids, queries_result_list\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "#  save_pair\n",
    "# ================================================================\n",
    "def save_pair(cfg, fold, queries_ids, queries_result_list):\n",
    "    pair = {}\n",
    "    for query_itr in range(len(queries_result_list)):\n",
    "        query_id = queries_ids[query_itr]\n",
    "        # Sort scores\n",
    "        top_hits = sorted(queries_result_list[query_itr], key=lambda x: x['score'], reverse=True)\n",
    "        corpus_id_list = [(d['corpus_id'], d['score']) for d in top_hits[0:cfg.n_neighbors]]\n",
    "        pair[query_id] = corpus_id_list\n",
    "        \n",
    "    path = cfg.output_dir+f\"{cfg.filename}_fold{fold}_top{cfg.n_neighbors}.pkl\"\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(pair, f)\n",
    "    print(f\"{path} saved!\")\n",
    "    \n",
    "# ===============================================================\n",
    "#  main\n",
    "# ===============================================================\n",
    "def main(cfg):\n",
    "    seed_everything(cfg)\n",
    "    df_content, df_topics = data_load(cfg)\n",
    "    queries, corpus = prepare_valid(df_content, df_topics)   \n",
    "    \n",
    "    for fold in cfg.n_fold:        \n",
    "        # set model\n",
    "        cfg.model = cfg.data_dir+ f\"fold{fold}/\" + cfg.base_model.replace(\"/\", \"-\") + \"_fine-tuned/\"\n",
    "        print(cfg.model)\n",
    "        model = FeatureExtractor(cfg)\n",
    "        model.to(device)\n",
    "        # get_pair\n",
    "        queries_ids, queries_result_list = get_pair(cfg, queries, corpus, model, device)\n",
    "        # save\n",
    "        save_pair(cfg, fold, queries_ids, queries_result_list)\n",
    "        del model, queries_ids, queries_result_list\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        print('\\033[32m'+f\"{cfg.model} finish.\"+'\\033[0m')\n",
    "\n",
    "# ===============================================================\n",
    "#  Execute\n",
    "# ===============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    for k, v in vars(args).items():\n",
    "        print(f\"{k}: {v}\")\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b4bec0c",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-03-13T07:20:39.702085Z",
     "iopub.status.busy": "2023-03-13T07:20:39.701787Z",
     "iopub.status.idle": "2023-03-13T07:20:39.713472Z",
     "shell.execute_reply": "2023-03-13T07:20:39.712554Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.01916,
     "end_time": "2023-03-13T07:20:39.715513",
     "exception": false,
     "start_time": "2023-03-13T07:20:39.696353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 2nd_stage_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 2nd_stage_model.py\n",
    "\n",
    "# ===============================================================\n",
    "#  Library\n",
    "# ===============================================================\n",
    "import os\n",
    "import gc\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import requests\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"device: {device}\")\n",
    "\n",
    "# ===============================================================\n",
    "#  args\n",
    "# ===============================================================\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--seed\", type=int, required=False, \n",
    "                        default=42)\n",
    "    parser.add_argument(\"--competition_dir\", type=str, required=False,\n",
    "                        default=\"/kaggle/input/learning-equality-curriculum-recommendations/\")\n",
    "    parser.add_argument(\"--data_dir\", type=str, required=False,\n",
    "                        default=\"/kaggle/input/2nd-stage-\")\n",
    "    parser.add_argument(\"--topic_dir\", type=str, required=False,\n",
    "                       default=\"/kaggle/working/1st_stage_model/\")\n",
    "    parser.add_argument(\"--output_dir\", type=str, required=False,\n",
    "                        default=\"/kaggle/working/2nd_stage_model/\")\n",
    "    parser.add_argument(\"--filename\", type=str, required=False, \n",
    "                        default=\"exp004\")    \n",
    "    parser.add_argument(\"--max_len\", type=int, required=False, \n",
    "                        default=256)    \n",
    "    parser.add_argument(\"--base_model\", type=str, required=False, \n",
    "                        default=\"sentence-transformers/all-MiniLM-L6-v2\")  \n",
    "    parser.add_argument(\"--batch_size\", type=int, required=False, \n",
    "                        default=64)    \n",
    "    parser.add_argument(\"--target_cols\", type=str, required=False, nargs=\"*\",\n",
    "                        default=[\"target\"])    \n",
    "    parser.add_argument(\"--n_fold\", type=int, required=False, nargs=\"*\",\n",
    "                        default=[0])    \n",
    "    parser.add_argument(\"--best_epoch\", type=int, required=False,\n",
    "                        default=3)    \n",
    "    args = parser.parse_args()\n",
    "    args.data_dir = args.data_dir + f\"{args.filename}/\"\n",
    "    if not os.path.exists(args.output_dir):\n",
    "        os.makedirs(args.output_dir)    \n",
    "    return args\n",
    "    \n",
    "# ===============================================================\n",
    "#  Utils\n",
    "# ===============================================================\n",
    "def seed_everything(cfg):\n",
    "    \"\"\"set seed\"\"\"\n",
    "    random.seed(cfg.seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(cfg.seed)\n",
    "    np.random.seed(cfg.seed)\n",
    "    torch.manual_seed(cfg.seed)\n",
    "    torch.cuda.manual_seed(cfg.seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "# ===============================================================\n",
    "#  tokenizer\n",
    "# ===============================================================\n",
    "def tokenizer(cfg):\n",
    "    cfg.tokenizer = AutoTokenizer.from_pretrained(\n",
    "        f'{cfg.data_dir}fold0/tokenizer',\n",
    "        is_fast=True)\n",
    "    return \n",
    "\n",
    "# ===============================================================\n",
    "#  DataLoading\n",
    "# ===============================================================\n",
    "def prepare_df(cfg, df_topics, df_content):\n",
    "    # load data\n",
    "    path = cfg.topic_dir+f\"exp006_fold0_top50.pkl\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        loaded_list = pickle.load(f)\n",
    "    df = pd.DataFrame(\n",
    "        [(query_id, corpus_id, score) for query_id, pairs in loaded_list.items() for corpus_id, score in pairs], \n",
    "        columns=['topic_id', 'predictions', 'score']\n",
    "        )\n",
    "    df = df.groupby(\"topic_id\")[[\"predictions\"]].agg(list).reset_index()\n",
    "    df[\"predictions\"] = df[\"predictions\"].apply(lambda x:\" \".join(x))\n",
    "    \n",
    "    # convert df for classification\n",
    "    df[\"predictions\"] = df.apply(\n",
    "    lambda x: \" \".join([str(val) for idx, val in enumerate(x) \\\n",
    "                        if pd.notna(val) and idx != df.columns.get_loc(\"topic_id\")]), axis=1\n",
    "    )\n",
    "    \n",
    "    df = df[[\"topic_id\", \"predictions\"]]\n",
    "    df = pd.merge(df, df_topics[[\"topic_id\", \"topic_sentence\", \"topic_length\"]], on=\"topic_id\", how=\"left\")\n",
    "    \n",
    "    df[\"predictions\"] = df[\"predictions\"].str.split()\n",
    "    df = df.explode(\"predictions\", ignore_index=True)\n",
    "    df = pd.merge(df, df_content[[\"id\", \"content_sentence\", \"content_length\"]].rename(columns={\"id\":\"predictions\"}),\n",
    "                  on=\"predictions\", how=\"left\")    \n",
    "    \n",
    "    # sort token \n",
    "    df[\"length\"] = df[\"topic_length\"] + df[\"content_length\"]\n",
    "    df.sort_values(by=\"length\", ascending=True, ignore_index=True, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def load_data(cfg):\n",
    "    df_topics = pd.read_csv(\"/kaggle/working/get_topic_context/topics.csv\").fillna({\"title\":\"\", \"description\":\"\"})\n",
    "    df_content = pd.read_csv(cfg.competition_dir+\"content.csv\").fillna(\n",
    "        {\"title\":\" \", \"description\":\"\", \"text\":\"\"})\n",
    "\n",
    "    # content sentence\n",
    "    df_content[\"content_sentence\"] = df_content[\"title\"] + cfg.tokenizer.sep_token + df_content[\"description\"]\n",
    "    print(df_content.isnull().sum())\n",
    "\n",
    "    # topic sentence\n",
    "    df_topics[\"topic_sentence\"] = df_topics[\"title\"] + cfg.tokenizer.sep_token +  df_topics[\"description\"] +\\\n",
    "    cfg.tokenizer.sep_token + df_topics[\"context\"]\n",
    "\n",
    "    df_topics[\"topic_sentence\"] = df_topics[\"topic_sentence\"].str.replace(\" >> \",  \" \")\n",
    "    \n",
    "    # encode sentence\n",
    "    df_content['content_length'] = [len(cfg.tokenizer(text)['input_ids']) \\\n",
    "                              for text in tqdm(df_content['content_sentence'].values, desc=\"encode content_sentence\")]\n",
    "    df_topics['topic_length'] = [len(cfg.tokenizer(text)['input_ids']) \\\n",
    "                             for text in tqdm(df_topics['topic_sentence'].values, desc=\"encode topic_sentence\")]\n",
    "    \n",
    "    df = prepare_df(cfg, df_topics, df_content)\n",
    "    print(\"df.shape: \", df.shape)\n",
    "    print(df.isnull().sum())\n",
    "    return df\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "#  Dataset\n",
    "# ===============================================================\n",
    "def prepare_input(cfg, text, text_pair):\n",
    "    inputs = cfg.tokenizer.encode_plus(\n",
    "        text, \n",
    "        text_pair,\n",
    "        return_tensors = None, \n",
    "        add_special_tokens = True, \n",
    "        max_length = cfg.max_len,\n",
    "        pad_to_max_length = True,\n",
    "        truncation = True\n",
    "    )\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype = torch.long)\n",
    "    return inputs\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.content_sentence = df[\"content_sentence\"].values\n",
    "        self.topic_sentence= df[\"topic_sentence\"].values\n",
    "    def __len__(self):\n",
    "        return len(self.topic_sentence)\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.cfg, self.topic_sentence[item], text_pair=self.content_sentence[item])\n",
    "        return inputs\n",
    "\n",
    "def collate(inputs):\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:,:mask_len]\n",
    "    return inputs\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "#  Model\n",
    "# ===============================================================\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "            self.config.hidden_dropout = 0\n",
    "            self.config.hidden_dropout_prob = 0\n",
    "            self.config.attention_dropout = 0\n",
    "            self.config.attetnion_probs_dropout_prob = 0\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel.from_config(self.config)\n",
    "        try:\n",
    "            self.model.gradient_checkpointing_enable()\n",
    "        except:\n",
    "            print(f'{cfg.base_model} does not support gradient checkpoint.')\n",
    "        self.pooler = MeanPooling()\n",
    "        self.fc = nn.Linear(self.config.hidden_size, len(cfg.target_cols))\n",
    "        self._init_weights(self.fc)\n",
    "        self.pooling = MeanPooling()\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.paddding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "            \n",
    "    def forward(self, inputs):\n",
    "        transformer_out = self.model(**inputs)\n",
    "        last_hidden_state = transformer_out.last_hidden_state\n",
    "        feature = self.pooling(last_hidden_state, inputs['attention_mask'])\n",
    "        output = self.fc(feature)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "# ===============================================================\n",
    "#  _loop_fn\n",
    "# ===============================================================\n",
    "def inference_fn(test_loader, model, device):\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    tk0 = tqdm(test_loader, total=len(test_loader))\n",
    "    for inputs in tk0:\n",
    "        inputs = collate(inputs)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        preds.append(y_preds.to('cpu').numpy())\n",
    "    predictions = np.concatenate(preds)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "#  loop_fn\n",
    "# ===============================================================\n",
    "def inference_loop(cfg, df, device):\n",
    "    df_dataset = TestDataset(cfg, df)\n",
    "    df_loader = DataLoader(df_dataset,\n",
    "                          batch_size=cfg.batch_size,\n",
    "                          shuffle=False,\n",
    "                          num_workers=0,\n",
    "                          pin_memory=True,\n",
    "                          drop_last=False)\n",
    "    \n",
    "    for fold in cfg.n_fold:\n",
    "        model = CustomModel(args, \n",
    "                            config_path=f'{cfg.data_dir}fold{fold}/'+'config.pth',\n",
    "                            pretrained=False)\n",
    "        state = torch.load(\n",
    "            f'{cfg.data_dir}fold{fold}/'+f\"{cfg.base_model.replace('/', '-')}_fold{fold}_epoch{cfg.best_epoch}_best.pth\",\n",
    "                        map_location=torch.device('cpu'))   \n",
    "        model.load_state_dict(state['model'])\n",
    "        prediction = inference_fn(df_loader, model, device)\n",
    "        torch.cuda.empty_cache()\n",
    "        df[\"target\"] = prediction\n",
    "        del model, state, prediction; gc.collect()\n",
    "        df.to_csv(f'{cfg.filename}_fold{fold}_submission.csv', index=False)\n",
    "        print('\\033[32m'+f\"{cfg.filename} fold{fold} finish.\"+'\\033[0m')\n",
    "\n",
    "    del df, df_dataset, df_loader\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "\n",
    "# ===============================================================\n",
    "#  main\n",
    "# ===============================================================\n",
    "def main(cfg):\n",
    "    seed_everything(cfg)\n",
    "    tokenizer(cfg)\n",
    "    df = load_data(cfg)    \n",
    "    inference_loop(cfg, df, device)\n",
    "                \n",
    "# ===============================================================\n",
    "#  Execution\n",
    "# ===============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    for k, v in vars(args).items():\n",
    "        print(f\"{k}: {v}\")\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23d1ce54",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-03-13T07:20:39.725782Z",
     "iopub.status.busy": "2023-03-13T07:20:39.725522Z",
     "iopub.status.idle": "2023-03-13T07:20:39.735463Z",
     "shell.execute_reply": "2023-03-13T07:20:39.734533Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.017519,
     "end_time": "2023-03-13T07:20:39.737454",
     "exception": false,
     "start_time": "2023-03-13T07:20:39.719935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 3rd_stage_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 3rd_stage_model.py\n",
    "\n",
    "# ================================================================\n",
    "#  Library\n",
    "# ================================================================\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "import torch\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "# ================================================================\n",
    "#  args\n",
    "# ================================================================\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--seed\", type=int, required=False, default=42)\n",
    "    parser.add_argument(\"--input_dir\", type=str, required=False, \n",
    "                        default=\"/kaggle/working/\")    \n",
    "    parser.add_argument(\"--output_dir\", type=str, required=False, \n",
    "                        default=\"/kaggle/working/\")\n",
    "    parser.add_argument(\"--pair_dir\", type=str, required=False, \n",
    "                        default=\"/kaggle/working/1st_stage_model/\")\n",
    "    parser.add_argument(\"--competition_dir\", type=str, required=False, \n",
    "                        default=\"/kaggle/input/learning-equality-curriculum-recommendations/\")\n",
    "    parser.add_argument(\"--data_dir\", type=str, required=False, \n",
    "                        default=\"/kaggle/input/3rd-stage-model/\")\n",
    "    parser.add_argument(\"--filenames\", type=str, required=False, nargs=\"*\",\n",
    "                       default=[])\n",
    "    parser.add_argument(\"--threshold\", type=float, required=False, default=0)\n",
    "    parser.add_argument(\"--add_top\", type=int, required=False, default=0)\n",
    "    return parser.parse_args()\n",
    "\n",
    "# ================================================================\n",
    "#  Utils\n",
    "# ================================================================\n",
    "def seed_everything(cfg):\n",
    "    \"\"\"set seed\"\"\"\n",
    "    random.seed(cfg.seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(cfg.seed)\n",
    "    np.random.seed(cfg.seed)\n",
    "    torch.manual_seed(cfg.seed)\n",
    "    torch.cuda.manual_seed(cfg.seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    \n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "# ================================================================\n",
    "#  Data_Loading\n",
    "# ================================================================\n",
    "def load_data(cfg):    \n",
    "    # base_pair\n",
    "    path = cfg.pair_dir+f\"exp006_fold0_top50.pkl\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        loaded_list = pickle.load(f)\n",
    "    df = pd.DataFrame(\n",
    "        [(query_id, corpus_id, score) for query_id, pairs in loaded_list.items() for corpus_id, score in pairs], \n",
    "        columns=['topic_id', 'content_ids', 'score']\n",
    "        )\n",
    "    \n",
    "    for i, filename in enumerate(cfg.filenames):\n",
    "        sub_df = pd.read_csv(cfg.input_dir+f\"{filename}_fold0_submission.csv\").rename(columns={\"predictions\":\"content_ids\", \n",
    "                                                                                               \"target\":f\"valid_pred_ver{i}\"})\n",
    "        df = pd.merge(df,\n",
    "                     sub_df[[\"topic_id\", \"content_ids\", f\"valid_pred_ver{i}\"]],\n",
    "                     on=[\"topic_id\", \"content_ids\"], how=\"left\")\n",
    "    # merge topic information\n",
    "    df_topics = pd.read_csv(cfg.competition_dir+\"topics.csv\")    \n",
    "    df_topics.rename(columns={\"id\":\"topic_id\",\n",
    "                              \"language\":\"topic_language\",\n",
    "                              \"channel\":\"topic_channel\",\n",
    "                              \"category\":\"topic_category\", \n",
    "                              \"level\":\"topic_level\"\n",
    "                              },\n",
    "                     inplace=True)\n",
    "    df = pd.merge(df, df_topics[[\"topic_id\", \"topic_language\", \"topic_channel\",\"topic_category\",\"topic_level\"]], \n",
    "                  on=\"topic_id\", how=\"left\")\n",
    "    \n",
    "    # merge content information\n",
    "    df_content = pd.read_csv(cfg.competition_dir+\"content.csv\")\n",
    "    df_content.rename(columns={\"language\":\"content_language\",\n",
    "                               \"kind\":\"content_kind\",\n",
    "                               \"id\":\"content_ids\"},\n",
    "                      inplace=True)\n",
    "    df = pd.merge(df, df_content[[\"content_ids\", \"content_language\",\"content_kind\"]],\n",
    "                  on=\"content_ids\", how=\"left\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "#  Feature_Engineering\n",
    "# ================================================================\n",
    "def do_fe(cfg, df):\n",
    "    # topicごとの統計量\n",
    "    for i in range(4):\n",
    "        sub_df = df.groupby(\"topic_id\")[f\"valid_pred_ver{i}\"].agg([\"mean\", \"min\", \"max\", \"std\"])\\\n",
    "                    .rename(columns=lambda x: f\"{x}_per_topic_ver{i}\").reset_index()\n",
    "        sub_df[f\"range_per_topic_ver{i}\"] = sub_df[f\"max_per_topic_ver{i}\"] - sub_df[f\"min_per_topic_ver{i}\"]\n",
    "        df = pd.merge(df, sub_df, on=\"topic_id\", how=\"left\")\n",
    "        \n",
    "    # category\n",
    "    df[\"topic_category_\"] = df[\"topic_category\"].map({\"aligned\":0, \"supplemental\":1})\n",
    "    \n",
    "    # kind\n",
    "    df[\"content_kind_\"] = df[\"content_kind\"].map({\"document\":0, \n",
    "                                                  \"video\":1,\n",
    "                                                  \"exercise\":2,\n",
    "                                                  \"audio\":3,\n",
    "                                                  \"html5\":4})\n",
    "    \n",
    "    # language\n",
    "    df[\"topic_language_is_en\"] = np.where(df[\"topic_language\"] == \"en\", 1, 0)\n",
    "    df[\"topic_language_is_es\"] = np.where(df[\"topic_language\"] == \"es\", 1, 0)\n",
    "\n",
    "    df[\"content_language_is_en\"] = np.where(df[\"content_language\"] == \"en\", 1, 0)\n",
    "    df[\"content_language_is_es\"] = np.where(df[\"content_language\"] == \"es\", 1, 0)\n",
    "\n",
    "    df[\"language_is_the_same\"] = np.where(df[\"topic_language\"] == df[\"content_language\"], 1, 0)\n",
    "    \n",
    "    \n",
    "    cfg.use_features = ['topic_level', 'score', 'valid_pred_ver0', 'valid_pred_ver1',\n",
    "           'valid_pred_ver2', 'valid_pred_ver3', 'mean_per_topic_ver0',\n",
    "           'min_per_topic_ver0', 'max_per_topic_ver0', 'std_per_topic_ver0',\n",
    "           'range_per_topic_ver0', 'mean_per_topic_ver1', 'min_per_topic_ver1',\n",
    "           'max_per_topic_ver1', 'std_per_topic_ver1', 'range_per_topic_ver1',\n",
    "           'mean_per_topic_ver2', 'min_per_topic_ver2', 'max_per_topic_ver2',\n",
    "           'std_per_topic_ver2', 'range_per_topic_ver2', 'mean_per_topic_ver3',\n",
    "           'min_per_topic_ver3', 'max_per_topic_ver3', 'std_per_topic_ver3',\n",
    "           'range_per_topic_ver3', 'topic_category_', 'content_kind_',\n",
    "           'topic_language_is_en', 'topic_language_is_es',\n",
    "           'content_language_is_en', 'content_language_is_es',\n",
    "           'language_is_the_same']\n",
    "    \n",
    "    cfg.cat_features = [\"topic_category_\", \"content_kind_\",  'topic_language_is_en', 'topic_language_is_es',\n",
    "           'content_language_is_en', 'content_language_is_es', 'topic_level',\n",
    "           'language_is_the_same']\n",
    "    return df\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "#  predict\n",
    "# ================================================================\n",
    "def lgb_predict(cfg, df):\n",
    "    predictions = []\n",
    "    for fold in tqdm(range(3)):\n",
    "        model_path = cfg.data_dir + f\"lgb_fold{fold}_model.pkl\"\n",
    "        with open(model_path, 'rb') as fin:\n",
    "            clf = pickle.load(fin)\n",
    "        prediction = clf.predict(df[cfg.use_features].values)\n",
    "        predictions.append(prediction)\n",
    "    predictions = np.median(predictions, axis=0)\n",
    "    df[\"sigmoid\"] = predictions\n",
    "    print(predictions)\n",
    "    return df\n",
    "\n",
    "# ================================================================\n",
    "#  get_submission\n",
    "# ================================================================\n",
    "def get_submission(cfg, df):\n",
    "    # それぞれのトピックで確率が大きいコンテンツを取得する\n",
    "    top_df = df.groupby('topic_id').apply(lambda x: x.sort_values(by='sigmoid', ascending=False\n",
    "                                                                 ).head(cfg.add_top)).reset_index(drop=True)\n",
    "    top_df = pd.DataFrame(top_df.groupby(\"topic_id\")[\"content_ids\"].agg(list)).reset_index()\n",
    "    top_df[\"content_ids\"] = top_df[\"content_ids\"].apply(lambda x: \" \".join(x))\n",
    "    \n",
    "    # 閾値より確率が大きいコンテンツを取得\n",
    "    df = df[df[\"sigmoid\"] > cfg.threshold].reset_index(drop=True)\n",
    "    df = df.groupby(\"topic_id\")[\"content_ids\"].agg(list).reset_index()\n",
    "    df[\"content_ids\"] = df[\"content_ids\"].apply(lambda x:\" \".join(x))\n",
    "    \n",
    "    # 各トピックに対して最低コンテンツを割り振るようにしたい\n",
    "    least_df = top_df[~top_df[\"topic_id\"].isin(df[\"topic_id\"].values)].reset_index(drop=True)\n",
    "    df = pd.concat([df, least_df], ignore_index=True)\n",
    "    \n",
    "    # save\n",
    "    df.to_csv(\"submission.csv\", index=False)\n",
    "    print('\\033[32m'+\"Save submission.csv\"+'\\033[0m')\n",
    "    \n",
    "# ================================================================\n",
    "#  main\n",
    "# ================================================================\n",
    "def main(cfg):\n",
    "    seed_everything(cfg)\n",
    "    df = load_data(cfg)\n",
    "    df = do_fe(cfg, df)\n",
    "    df = lgb_predict(cfg, df)\n",
    "    get_submission(cfg, df)\n",
    "    \n",
    "# ================================================================\n",
    "#  execute\n",
    "# ================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    for k, v in vars(args).items():\n",
    "        print(f\"{k}: {v}\")\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aed0b55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T07:20:39.748504Z",
     "iopub.status.busy": "2023-03-13T07:20:39.747017Z",
     "iopub.status.idle": "2023-03-13T07:20:42.102612Z",
     "shell.execute_reply": "2023-03-13T07:20:42.101382Z"
    },
    "papermill": {
     "duration": 2.363488,
     "end_time": "2023-03-13T07:20:42.105313",
     "exception": false,
     "start_time": "2023-03-13T07:20:39.741825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "seed: 42\r\n",
      "competition_dir: /kaggle/input/learning-equality-curriculum-recommendations/\r\n",
      "output_dir: /kaggle/working/get_topic_context/\r\n",
      "debug: False\r\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:00<00:00, 28.09it/s]\r\n",
      "topic_id       0\r\n",
      "content_ids    0\r\n",
      "channel        0\r\n",
      "title          0\r\n",
      "description    0\r\n",
      "context        0\r\n",
      "dtype: int64\r\n",
      "['Khan Academy (български език)  Наука  Физика  Открития и проекти  Откриването на резисторите'\r\n",
      " 'Khan Academy (Português (Brasil))  Matemática por ano (Alinhada à BNCC)  9º Ano  Álgebra: funções  Entradas e saídas de uma função']\r\n"
     ]
    }
   ],
   "source": [
    "!python get_topic_context.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d25422e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T07:20:42.118111Z",
     "iopub.status.busy": "2023-03-13T07:20:42.117722Z",
     "iopub.status.idle": "2023-03-13T07:26:40.578318Z",
     "shell.execute_reply": "2023-03-13T07:26:40.577077Z"
    },
    "papermill": {
     "duration": 358.470217,
     "end_time": "2023-03-13T07:26:40.581142",
     "exception": false,
     "start_time": "2023-03-13T07:20:42.110925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "device: cuda\r\n",
      "seed: 42\r\n",
      "competition_dir: /kaggle/input/learning-equality-curriculum-recommendations/\r\n",
      "data_dir: /kaggle/input/1st-stage-exp006/\r\n",
      "topic_dir: /kaggle/working/get_topic_context/\r\n",
      "output_dir: /kaggle/working/1st_stage_model/\r\n",
      "base_model: sentence-transformers/all-mpnet-base-v2\r\n",
      "filename: exp006\r\n",
      "max_len: 128\r\n",
      "n_neighbors: 50\r\n",
      "corpus_chunk_size: 40000\r\n",
      "batch_size: 96\r\n",
      "n_fold: [0]\r\n",
      "debug: False\r\n",
      "========== Data Loading ==========\r\n",
      "df_topics:  (5, 8)\r\n",
      "df_content:  (154047, 10)\r\n",
      "Input Sentence Example:\r\n",
      "========== Topics ==========\r\n",
      "['Откриването на резисторите</s>Изследване на материали, които предизвикват намаление в отклонението, когато се свържат последователно с нашия измервателен уред. </s>Khan Academy (български език)  Наука  Физика  Открития и проекти  Откриването на резисторите', 'Entradas e saídas de uma função</s>Entenda um pouco mais sobre funções.</s>Khan Academy (Português (Brasil))  Matemática por ano (Alinhada à BNCC)  9º Ano  Álgebra: funções  Entradas e saídas de uma função']\r\n",
      "========== Content ==========\r\n",
      "['Sumar números de varios dígitos: 48,029+233,930 </s>Suma 48,029+233,930 mediante el algoritmo estándar.\\n\\n', 'Trovare i fattori di un numero</s>Sal trova i fattori di 120.\\n\\n']\r\n",
      "topic_id          0\r\n",
      "content_ids       0\r\n",
      "channel           0\r\n",
      "title             0\r\n",
      "description       0\r\n",
      "context           0\r\n",
      "sentence          0\r\n",
      "topic_sentence    0\r\n",
      "dtype: int64\r\n",
      "/kaggle/input/1st-stage-exp006/fold0/sentence-transformers-all-mpnet-base-v2_fine-tuned/\r\n",
      "Batches: 100%|████████████████████████████████████| 1/1 [00:01<00:00,  1.54s/it]\r\n",
      "encode corpus & keep pairs: 100%|█████████████████| 4/4 [05:20<00:00, 80.03s/it]\r\n",
      "/kaggle/working/1st_stage_model/exp006_fold0_top50.pkl saved!\r\n",
      "\u001b[32m/kaggle/input/1st-stage-exp006/fold0/sentence-transformers-all-mpnet-base-v2_fine-tuned/ finish.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python 1st_stage_model.py\\\n",
    "--n_neighbors 50\\\n",
    "--n_fold 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71567eab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T07:26:40.594248Z",
     "iopub.status.busy": "2023-03-13T07:26:40.593849Z",
     "iopub.status.idle": "2023-03-13T07:27:28.693799Z",
     "shell.execute_reply": "2023-03-13T07:27:28.692589Z"
    },
    "papermill": {
     "duration": 48.109367,
     "end_time": "2023-03-13T07:27:28.696327",
     "exception": false,
     "start_time": "2023-03-13T07:26:40.586960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "device: cuda\r\n",
      "seed: 42\r\n",
      "competition_dir: /kaggle/input/learning-equality-curriculum-recommendations/\r\n",
      "data_dir: /kaggle/input/2nd-stage-exp004/\r\n",
      "topic_dir: /kaggle/working/1st_stage_model/\r\n",
      "output_dir: /kaggle/working/2nd_stage_model/\r\n",
      "filename: exp004\r\n",
      "max_len: 256\r\n",
      "base_model: sentence-transformers/all-MiniLM-L6-v2\r\n",
      "batch_size: 64\r\n",
      "target_cols: ['target']\r\n",
      "n_fold: [0]\r\n",
      "best_epoch: 3\r\n",
      "id                      0\r\n",
      "title                   0\r\n",
      "description             0\r\n",
      "kind                    0\r\n",
      "text                    0\r\n",
      "language                0\r\n",
      "copyright_holder    82226\r\n",
      "license             80012\r\n",
      "content_sentence        0\r\n",
      "dtype: int64\r\n",
      "encode content_sentence: 100%|████████| 154047/154047 [00:28<00:00, 5419.89it/s]\r\n",
      "encode topic_sentence: 100%|████████████████████| 5/5 [00:00<00:00, 1230.29it/s]\r\n",
      "df.shape:  (250, 7)\r\n",
      "topic_id            0\r\n",
      "predictions         0\r\n",
      "topic_sentence      0\r\n",
      "topic_length        0\r\n",
      "content_sentence    0\r\n",
      "content_length      0\r\n",
      "length              0\r\n",
      "dtype: int64\r\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:00<00:00,  4.19it/s]\r\n",
      "\u001b[32mexp004 fold0 finish.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python 2nd_stage_model.py\\\n",
    "--filename exp004\\\n",
    "--base_model sentence-transformers/all-MiniLM-L6-v2\\\n",
    "--best_epoch 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cc36b22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T07:27:28.739051Z",
     "iopub.status.busy": "2023-03-13T07:27:28.738018Z",
     "iopub.status.idle": "2023-03-13T07:28:20.987413Z",
     "shell.execute_reply": "2023-03-13T07:28:20.986208Z"
    },
    "papermill": {
     "duration": 52.273197,
     "end_time": "2023-03-13T07:28:20.990019",
     "exception": false,
     "start_time": "2023-03-13T07:27:28.716822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "device: cuda\r\n",
      "seed: 42\r\n",
      "competition_dir: /kaggle/input/learning-equality-curriculum-recommendations/\r\n",
      "data_dir: /kaggle/input/2nd-stage-exp006/\r\n",
      "topic_dir: /kaggle/working/1st_stage_model/\r\n",
      "output_dir: /kaggle/working/2nd_stage_model/\r\n",
      "filename: exp006\r\n",
      "max_len: 256\r\n",
      "base_model: sentence-transformers/all-mpnet-base-v2\r\n",
      "batch_size: 64\r\n",
      "target_cols: ['target']\r\n",
      "n_fold: [0]\r\n",
      "best_epoch: 3\r\n",
      "id                      0\r\n",
      "title                   0\r\n",
      "description             0\r\n",
      "kind                    0\r\n",
      "text                    0\r\n",
      "language                0\r\n",
      "copyright_holder    82226\r\n",
      "license             80012\r\n",
      "content_sentence        0\r\n",
      "dtype: int64\r\n",
      "encode content_sentence: 100%|████████| 154047/154047 [00:27<00:00, 5689.53it/s]\r\n",
      "encode topic_sentence: 100%|████████████████████| 5/5 [00:00<00:00, 1197.96it/s]\r\n",
      "df.shape:  (250, 7)\r\n",
      "topic_id            0\r\n",
      "predictions         0\r\n",
      "topic_sentence      0\r\n",
      "topic_length        0\r\n",
      "content_sentence    0\r\n",
      "content_length      0\r\n",
      "length              0\r\n",
      "dtype: int64\r\n",
      "sentence-transformers/all-mpnet-base-v2 does not support gradient checkpoint.\r\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:02<00:00,  1.92it/s]\r\n",
      "\u001b[32mexp006 fold0 finish.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python 2nd_stage_model.py\\\n",
    "--filename exp006\\\n",
    "--base_model sentence-transformers/all-mpnet-base-v2\\\n",
    "--best_epoch 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b89dfef4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T07:28:21.059830Z",
     "iopub.status.busy": "2023-03-13T07:28:21.058858Z",
     "iopub.status.idle": "2023-03-13T07:29:25.968741Z",
     "shell.execute_reply": "2023-03-13T07:29:25.967512Z"
    },
    "papermill": {
     "duration": 64.947539,
     "end_time": "2023-03-13T07:29:25.971579",
     "exception": false,
     "start_time": "2023-03-13T07:28:21.024040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "device: cuda\r\n",
      "seed: 42\r\n",
      "competition_dir: /kaggle/input/learning-equality-curriculum-recommendations/\r\n",
      "data_dir: /kaggle/input/2nd-stage-exp007/\r\n",
      "topic_dir: /kaggle/working/1st_stage_model/\r\n",
      "output_dir: /kaggle/working/2nd_stage_model/\r\n",
      "filename: exp007\r\n",
      "max_len: 256\r\n",
      "base_model: xlm-roberta-base\r\n",
      "batch_size: 64\r\n",
      "target_cols: ['target']\r\n",
      "n_fold: [0]\r\n",
      "best_epoch: 3\r\n",
      "id                      0\r\n",
      "title                   0\r\n",
      "description             0\r\n",
      "kind                    0\r\n",
      "text                    0\r\n",
      "language                0\r\n",
      "copyright_holder    82226\r\n",
      "license             80012\r\n",
      "content_sentence        0\r\n",
      "dtype: int64\r\n",
      "encode content_sentence: 100%|████████| 154047/154047 [00:28<00:00, 5343.36it/s]\r\n",
      "encode topic_sentence: 100%|████████████████████| 5/5 [00:00<00:00, 1147.36it/s]\r\n",
      "df.shape:  (250, 7)\r\n",
      "topic_id            0\r\n",
      "predictions         0\r\n",
      "topic_sentence      0\r\n",
      "topic_length        0\r\n",
      "content_sentence    0\r\n",
      "content_length      0\r\n",
      "length              0\r\n",
      "dtype: int64\r\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  2.44it/s]\r\n",
      "\u001b[32mexp007 fold0 finish.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python 2nd_stage_model.py\\\n",
    "--filename exp007\\\n",
    "--base_model xlm-roberta-base\\\n",
    "--best_epoch 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de45a80e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T07:29:26.069805Z",
     "iopub.status.busy": "2023-03-13T07:29:26.069431Z",
     "iopub.status.idle": "2023-03-13T07:30:28.816844Z",
     "shell.execute_reply": "2023-03-13T07:30:28.815623Z"
    },
    "papermill": {
     "duration": 62.799649,
     "end_time": "2023-03-13T07:30:28.819410",
     "exception": false,
     "start_time": "2023-03-13T07:29:26.019761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "device: cuda\r\n",
      "seed: 42\r\n",
      "competition_dir: /kaggle/input/learning-equality-curriculum-recommendations/\r\n",
      "data_dir: /kaggle/input/2nd-stage-exp008/\r\n",
      "topic_dir: /kaggle/working/1st_stage_model/\r\n",
      "output_dir: /kaggle/working/2nd_stage_model/\r\n",
      "filename: exp008\r\n",
      "max_len: 256\r\n",
      "base_model: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\r\n",
      "batch_size: 64\r\n",
      "target_cols: ['target']\r\n",
      "n_fold: [0]\r\n",
      "best_epoch: 3\r\n",
      "id                      0\r\n",
      "title                   0\r\n",
      "description             0\r\n",
      "kind                    0\r\n",
      "text                    0\r\n",
      "language                0\r\n",
      "copyright_holder    82226\r\n",
      "license             80012\r\n",
      "content_sentence        0\r\n",
      "dtype: int64\r\n",
      "encode content_sentence: 100%|████████| 154047/154047 [00:28<00:00, 5487.73it/s]\r\n",
      "encode topic_sentence: 100%|████████████████████| 5/5 [00:00<00:00, 1095.40it/s]\r\n",
      "df.shape:  (250, 7)\r\n",
      "topic_id            0\r\n",
      "predictions         0\r\n",
      "topic_sentence      0\r\n",
      "topic_length        0\r\n",
      "content_sentence    0\r\n",
      "content_length      0\r\n",
      "length              0\r\n",
      "dtype: int64\r\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  2.46it/s]\r\n",
      "\u001b[32mexp008 fold0 finish.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python 2nd_stage_model.py\\\n",
    "--filename exp008\\\n",
    "--base_model sentence-transformers/paraphrase-multilingual-mpnet-base-v2\\\n",
    "--best_epoch 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ec6f5df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T07:30:28.949506Z",
     "iopub.status.busy": "2023-03-13T07:30:28.948442Z",
     "iopub.status.idle": "2023-03-13T07:30:46.525344Z",
     "shell.execute_reply": "2023-03-13T07:30:46.524122Z"
    },
    "papermill": {
     "duration": 17.644399,
     "end_time": "2023-03-13T07:30:46.527888",
     "exception": false,
     "start_time": "2023-03-13T07:30:28.883489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "seed: 42\r\n",
      "input_dir: /kaggle/working/\r\n",
      "output_dir: /kaggle/working/\r\n",
      "pair_dir: /kaggle/working/1st_stage_model/\r\n",
      "competition_dir: /kaggle/input/learning-equality-curriculum-recommendations/\r\n",
      "data_dir: /kaggle/input/3rd-stage-model/\r\n",
      "filenames: ['exp004', 'exp006', 'exp007', 'exp008']\r\n",
      "threshold: 0.1\r\n",
      "add_top: 1\r\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 57.97it/s]\r\n",
      "[0.51103137 0.73713227 0.09132739 0.05130519 0.21499051 0.0311109\r\n",
      " 0.04670557 0.02644748 0.06166608 0.01587486 0.08213433 0.02167364\r\n",
      " 0.0261566  0.02579991 0.03905639 0.02532873 0.02702754 0.03703016\r\n",
      " 0.04578561 0.04587744 0.030566   0.02216115 0.0153179  0.02826464\r\n",
      " 0.01696076 0.02311777 0.02024259 0.02239036 0.02848879 0.02160788\r\n",
      " 0.02094879 0.01812745 0.01574937 0.38935418 0.01325655 0.01673222\r\n",
      " 0.01460603 0.01618934 0.03534195 0.02950377 0.01626258 0.01459344\r\n",
      " 0.02418695 0.00954749 0.01237554 0.01610195 0.02180731 0.07511695\r\n",
      " 0.01499629 0.00884792 0.89068717 0.84743952 0.05383389 0.0996119\r\n",
      " 0.06154957 0.83232734 0.82164296 0.70049843 0.05391194 0.06718329\r\n",
      " 0.04981532 0.19133018 0.06256829 0.01386586 0.01374008 0.01795898\r\n",
      " 0.0069861  0.00899996 0.02658026 0.01793766 0.01149713 0.0072142\r\n",
      " 0.0550592  0.00953774 0.01260953 0.01226997 0.00644948 0.0115782\r\n",
      " 0.00748618 0.00996445 0.03134153 0.01280848 0.01091799 0.00713919\r\n",
      " 0.01615393 0.01240844 0.00643693 0.00981144 0.00298422 0.01152997\r\n",
      " 0.00641285 0.00822926 0.00881726 0.01239021 0.01540232 0.00359817\r\n",
      " 0.00271343 0.01134806 0.00452335 0.00290377 0.96625847 0.01519969\r\n",
      " 0.01622615 0.01099078 0.01099078 0.01657145 0.01031642 0.01108569\r\n",
      " 0.00957058 0.0091092  0.0091092  0.01131116 0.00970542 0.00853703\r\n",
      " 0.00853703 0.00853703 0.00901991 0.01283041 0.00904983 0.00904983\r\n",
      " 0.00904983 0.00685026 0.00904983 0.00904983 0.00837851 0.00775387\r\n",
      " 0.00827199 0.00685026 0.00734144 0.0068302  0.0068302  0.00734144\r\n",
      " 0.0068302  0.0068302  0.00790889 0.00734144 0.00599406 0.00586214\r\n",
      " 0.00510484 0.00548765 0.00660006 0.00584823 0.00510484 0.00764219\r\n",
      " 0.00764219 0.00764219 0.00510484 0.00584823 0.00510484 0.00510484\r\n",
      " 0.0609199  0.05574976 0.85740516 0.05759911 0.0463285  0.83771401\r\n",
      " 0.06157143 0.80801956 0.12669291 0.82730165 0.02221272 0.813198\r\n",
      " 0.04269514 0.00987444 0.04054601 0.0105585  0.01998933 0.01689444\r\n",
      " 0.00610654 0.01180007 0.01295473 0.01235011 0.01028152 0.01235011\r\n",
      " 0.00586663 0.00909361 0.00452824 0.00588743 0.00683534 0.00541867\r\n",
      " 0.00426723 0.01045469 0.0105031  0.00859075 0.02781875 0.00512552\r\n",
      " 0.01279056 0.01233647 0.00464366 0.00668481 0.00566653 0.012108\r\n",
      " 0.01116449 0.00539228 0.00728598 0.00695644 0.00843274 0.00695644\r\n",
      " 0.005128   0.00859924 0.53119593 0.95211517 0.01878533 0.01878533\r\n",
      " 0.01786409 0.01150464 0.00898519 0.00898519 0.00348111 0.0023782\r\n",
      " 0.00247847 0.00207159 0.00486164 0.00326065 0.00495687 0.00229032\r\n",
      " 0.00353266 0.00214561 0.00325125 0.00325125 0.00327616 0.00325125\r\n",
      " 0.00325125 0.00335451 0.00627857 0.00318382 0.00327616 0.00247847\r\n",
      " 0.00331424 0.00247847 0.0023782  0.00214561 0.00627857 0.00206975\r\n",
      " 0.00335451 0.00229032 0.00318382 0.00292172 0.00214561 0.00258022\r\n",
      " 0.00214561 0.00326065 0.00237383 0.00237383 0.00335451 0.00247847\r\n",
      " 0.00326065 0.00247847 0.00247847 0.00247847]\r\n",
      "\u001b[32mSave submission.csv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python 3rd_stage_model.py\\\n",
    "--filenames exp004 exp006 exp007 exp008\\\n",
    "--threshold 0.1\\\n",
    "--add_top 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eff43e82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T07:30:46.655200Z",
     "iopub.status.busy": "2023-03-13T07:30:46.654198Z",
     "iopub.status.idle": "2023-03-13T07:30:46.677610Z",
     "shell.execute_reply": "2023-03-13T07:30:46.676654Z"
    },
    "papermill": {
     "duration": 0.089188,
     "end_time": "2023-03-13T07:30:46.679659",
     "exception": false,
     "start_time": "2023-03-13T07:30:46.590471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>content_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_1108dd0c7a5d c_76231f9d0b5e c_376c5a8eb028 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_00068291e9a4</td>\n",
       "      <td>c_ac1672cdcd2c c_89ce9367be10 c_ebb7fdf10a7e c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_00069b63a70a</td>\n",
       "      <td>c_11a1dc0bfb99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_0006d41a73a8</td>\n",
       "      <td>c_5e375cf14c47 c_d7a0d7eaf799 c_1c57a1316568 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_4054df11a74e</td>\n",
       "      <td>c_f2d184a98231 c_3695c5dc1df6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic_id                                        content_ids\n",
       "0  t_00004da3a1b2  c_1108dd0c7a5d c_76231f9d0b5e c_376c5a8eb028 c...\n",
       "1  t_00068291e9a4  c_ac1672cdcd2c c_89ce9367be10 c_ebb7fdf10a7e c...\n",
       "2  t_00069b63a70a                                     c_11a1dc0bfb99\n",
       "3  t_0006d41a73a8  c_5e375cf14c47 c_d7a0d7eaf799 c_1c57a1316568 c...\n",
       "4  t_4054df11a74e                      c_f2d184a98231 c_3695c5dc1df6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2364c3",
   "metadata": {
    "papermill": {
     "duration": 0.062327,
     "end_time": "2023-03-13T07:30:46.804557",
     "exception": false,
     "start_time": "2023-03-13T07:30:46.742230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 616.183488,
   "end_time": "2023-03-13T07:30:47.489399",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-13T07:20:31.305911",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
